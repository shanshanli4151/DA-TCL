{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26c3eac-76ba-4aa8-8924-3e676f30b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modelsli1 import *\n",
    "from ihdp_data import *\n",
    "import json\n",
    "import numpy as np\n",
    "from ate import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73c4ed08-3ffe-4dcd-a6a1-8bfe2843d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4bdd3b2-500f-4b90-b90d-72aba1288847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(ker, X1, X2, gamma):\n",
    "    \"\"\"\n",
    "    Kernel function to compute kernel matrix based on kernel type.\n",
    "    :param ker: 'linear' | 'rbf'\n",
    "    :param X1: First dataset (Xs or Xt)\n",
    "    :param X2: Second dataset (Xs or Xt)\n",
    "    :param gamma: Kernel bandwidth (only used for 'rbf')\n",
    "    :return: Computed kernel matrix\n",
    "    \"\"\"\n",
    "    K = None\n",
    "    if ker == 'linear':\n",
    "        if X2 is not None:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1), np.asarray(X2))\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1))\n",
    "    elif ker == 'rbf':\n",
    "        if X2 is not None:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1), np.asarray(X2), gamma)\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1), None, gamma)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9518a8f-5647-454d-a9fd-ee449401011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMM:\n",
    "    def __init__(self, kernel_type='linear', gamma=1.0, B=1.0, eps=None):\n",
    "        '''\n",
    "        Initialization function\n",
    "        :param kernel_type: 'linear' | 'rbf'\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        :param B: bound for beta\n",
    "        :param eps: bound for sigma_beta\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.gamma = gamma\n",
    "        self.B = B\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, Xs, Xt):\n",
    "        '''\n",
    "        Fit source and target using KMM (compute the coefficients)\n",
    "        :param Xs: ns * dim\n",
    "        :param Xt: nt * dim\n",
    "        :return: Coefficients (Pt / Ps) value vector (Beta in the paper)\n",
    "        '''\n",
    "        ns = Xs.shape[0]\n",
    "        nt = Xt.shape[0]\n",
    "        if self.eps is None:\n",
    "            self.eps = self.B / np.sqrt(ns)\n",
    "        \n",
    "        # Compute kernel matrix\n",
    "        K = kernel(self.kernel_type, Xs, None, self.gamma)\n",
    "        kappa = np.sum(kernel(self.kernel_type, Xs, Xt, self.gamma) * float(ns) / float(nt), axis=1)\n",
    "        \n",
    "        # Set up and solve the quadratic programming problem\n",
    "        K = matrix(K.astype(np.double))\n",
    "        kappa = matrix(kappa.astype(np.double))\n",
    "        G = matrix(np.r_[np.ones((1, ns)), -np.ones((1, ns)), np.eye(ns), -np.eye(ns)])\n",
    "        h = matrix(np.r_[ns * (1 + self.eps), ns * (self.eps - 1), self.B * np.ones((ns,)), np.zeros((ns,))])\n",
    "\n",
    "        sol = solvers.qp(K, -kappa, G, h)\n",
    "        beta = np.array(sol['x'])\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050faff9-3845-45a0-946d-e322a69c0de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmm(Xs, Ys, Xt, Yt, kernel_type='rbf', gamma=1.0, B=1.0):\n",
    "    \"\"\"\n",
    "    Apply KMM to source and target domain data to compute new source data.\n",
    "    :param Xs: Source data (ns * dim)\n",
    "    :param Ys: Source labels (ns * 1)\n",
    "    :param Xt: Target data (nt * dim)\n",
    "    :param Yt: Target labels (nt * 1)\n",
    "    :param kernel_type: 'linear' | 'rbf', default is 'rbf'\n",
    "    :param gamma: Bandwidth parameter for 'rbf' kernel, default is 1.0\n",
    "    :param B: Bound for beta, default is 1.0\n",
    "    :return: New source data Xs_new after applying KMM\n",
    "    \"\"\"\n",
    "    # Initialize KMM model\n",
    "    kmm = KMM(kernel_type=kernel_type, gamma=gamma, B=B)\n",
    "    \n",
    "    # Fit KMM model to compute the coefficients\n",
    "    beta = kmm.fit(Xs, Xt)\n",
    "    \n",
    "    # Compute the new source data Xs_new by scaling the original Xs with beta\n",
    "    Xs_new = beta * Xs\n",
    "    \n",
    "    return Xs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2efdbf-96ff-4d93-87a8-a35c6b833050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimate(q_t0, q_t1, g, t, y_dragon, index, eps, truncate_level=0.01):\n",
    "    \"\"\"\n",
    "    getting the back door adjustment & TMLE estimation\n",
    "    \"\"\"\n",
    "\n",
    "    psi_n = psi_naive(q_t0, q_t1, g, t, y_dragon, truncate_level=truncate_level)\n",
    "    ipw_n, dr_n = psi_weighting(q_t0, q_t1, g, t, y_dragon, truncate_level=truncate_level)\n",
    "    psi_tmle, psi_tmle_std, eps_hat, initial_loss, final_loss, g_loss = psi_tmle_cont_outcome(q_t0, q_t1, g, t,\n",
    "                                                                                              y_dragon,\n",
    "                                                                                              truncate_level=truncate_level)\n",
    "    return psi_n, psi_tmle, initial_loss, final_loss, g_loss,ipw_n, dr_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2b5f15-5839-45a0-81c1-9cecce686a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5136fc-46d2-4c7c-b1f9-4feba9eacbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_output(yt_hat, t, y, y_scaler, x, index):\n",
    "    \"\"\"\n",
    "        Split output into dictionary for easier use in estimation#为了以后方便使用\n",
    "        Args:\n",
    "            yt_hat: Generated prediction，生成的预测，有两个y0与y1\n",
    "            t: Binary treatment assignments\n",
    "            y: Treatment outcomes,实际已有的数据\n",
    "            y_scaler: Scaled treatment outcomes#标准化后的\n",
    "            x: Covariates\n",
    "            index: Index in data\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of all needed data\n",
    "    \"\"\"\n",
    "    yt_hat = yt_hat.detach().cpu().numpy()#将 yt_hat 从 PyTorch 的张量转换成 NumPy 数组（脱离计算图，移到 CPU）。\n",
    "    q_t0 = y_scaler.inverse_transform(yt_hat[:, 0].reshape(-1, 1).copy())#归一化后的对照组潜在预测结果\n",
    "    q_t1 = y_scaler.inverse_transform(yt_hat[:, 1].reshape(-1, 1).copy())\n",
    "    g = yt_hat[:, 2].copy()# 提取倾向得分\n",
    "\n",
    "    if yt_hat.shape[1] == 4:\n",
    "        eps = yt_hat[:, 3][0]# 如果 `yt_hat` 有第四列，提取 `eps`\n",
    "    else:\n",
    "        eps = np.zeros_like(yt_hat[:, 2])# 否则，`eps` 初始化为全零\n",
    "#scaler.inverse_transform,归一化\n",
    "#copy()：浅复制，将另一个对象关联到这个对象的副本，即复制这个对象内部的值(当内部的值不是可变对象的时候)\n",
    "\n",
    "    y = y_scaler.inverse_transform(y.copy())#逆归一化\n",
    "    var = \"average propensity for treated: {} and untreated: {}\".format(g[t.squeeze() == 1.].mean(),\n",
    "                                                                        g[t.squeeze() == 0.].mean())\n",
    "    print(var)\n",
    "\n",
    "    return {'q_t0': q_t0, 'q_t1': q_t1, 'g': g, 't': t, 'y': y, 'x': x, 'index': index, 'eps': eps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "844f834c-887f-4536-bc50-370e220a111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, optimizer, criterion,valid_loader= None,l1_reg = None):\n",
    "    \"\"\"\n",
    "    Trains network for one epoch in batches.\n",
    "    Args:\n",
    "        train_loader: Data loader for training set.\n",
    "        net: Neural network model.\n",
    "        optimizer: Optimizer (e.g. SGD).优化器\n",
    "        criterion: Loss function (e.g. cross-entropy loss).\n",
    "    \"\"\"\n",
    "\n",
    "    avg_loss = 0\n",
    "    # iterate through batches，迭代处理\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]，获取输入;data 是 [inputs， labels] 的列表\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients，参数梯度归零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize，前进、反馈、最优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if l1_reg is not None:\n",
    "            l1_penalty = l1_reg * sum([p.abs().sum() for p in net.parameters()])\n",
    "            loss+= l1_penalty\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of loss and accuracy，跟踪损失和准确性\n",
    "        avg_loss += loss\n",
    "\n",
    "    valid_loss = None\n",
    "    if valid_loader is not None:\n",
    "        valid_loss = 0.0\n",
    "        net.eval()     # Optional when not using Model Specific layer，不使用模型特定图层时可选\n",
    "        for data, labels in valid_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data, labels = data.cuda(), labels.cuda()\n",
    "            \n",
    "            target = net(data)\n",
    "            loss = criterion(target,labels)\n",
    "            if l1_reg is not None:\n",
    "                loss+= l1_reg * sum([p.abs().sum() for p in net.parameters()]) \n",
    "            valid_loss += loss\n",
    "        valid_loss = valid_loss/len(valid_loader)\n",
    "    return avg_loss / len(train_loader), valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478231d4-53cb-414d-90ad-d1a013f2796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_dragons(t, y_unscaled, x, net,seed = 0, targeted_regularization=True, output_dir='',\n",
    "                              knob_loss=dragonnet_loss_binarycross, ratio=1., dragon='', val_split=0.2, batch_size=64,lr =1e-3,l1_reg = None):\n",
    "    \"\"\"\n",
    "    Method for training dragonnet and tarnet and predicting new results\n",
    "    Returns:\n",
    "        Outputs on train and test data\n",
    "用于训练 dragonnet 和 tarnet 并预测新结果的方法，\n",
    "返回： train 和 test 数据的输出\n",
    "    \"\"\"    \n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    verbose = 0\n",
    "    y_scaler = StandardScaler()\n",
    "    y = y_scaler.fit_transform(y_unscaled)\n",
    "    train_outputs = []#定义元组，将输出存在里面\n",
    "    test_outputs = []\n",
    "\n",
    "\n",
    "    # Which loss to use for training the network，选择损失函数，在dragonnet_loss与普通knob_loss中选取\n",
    "    if targeted_regularization:\n",
    "        loss = make_tarreg_loss(ratio=ratio, dragonnet_loss=knob_loss)\n",
    "    else:\n",
    "        loss = knob_loss\n",
    "\n",
    "    # loss = knob_loss\n",
    "    # for reporducing the IHDP experimemt\n",
    "\n",
    "    i = seed\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    random.seed(i)\n",
    "    \n",
    "\n",
    "    \n",
    " \n",
    " # Get the data and optionally divide into train and test set，获取数据并可选择划分为训练集和测试集\n",
    "#不同与base,trans都不同，与trans相比多了一if\n",
    "#ratio惩罚函数的一个比重\n",
    "    if ratio == 0:\n",
    "        train_index = np.arange(x.shape[0])\n",
    "        test_index = train_index\n",
    "    else:\n",
    "        train_index, test_index = train_test_split(np.arange(x.shape[0]), test_size=ratio, random_state=seed)\n",
    "        #print(f'test_index {test_index}')\n",
    "   \n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    t_train, t_test = t[train_index], t[test_index]\n",
    "\n",
    "    yt_train = np.concatenate([y_train, t_train], 1)\n",
    "\n",
    "    yt_test = np.concatenate([y_test, t_test], 1)\n",
    "\n",
    "    # Create data loader to pass onto training method，创建数据加载器以传递到训练方法\n",
    "    tensors_train = torch.from_numpy(x_train).float().to(device), torch.from_numpy(yt_train).float().to(device)\n",
    "    train_size = int((val_split) * len(TensorDataset(*tensors_train)))\n",
    "    val_size = int(len(TensorDataset(*tensors_train))-train_size)\n",
    "    train_set, valid_set = random_split(TensorDataset(*tensors_train),[train_size,val_size])\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=500)\n",
    "\n",
    "    import time;\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Configuring optimizers，配置优化器，惩罚迭代过程\n",
    "    # Training the networks first for 100 epochs with the Adam optimizer and，首先使用 Adam 优化器训练网络 100 个 epoch\n",
    "    # then for 300 epochs with the SGD optimizer.Adam 用于初始阶段，SGD 用于更长的训练阶段\n",
    "    epochs1 = 100\n",
    "    epochs2 = 300\n",
    "    # Add L2 regularization to t0 and t1 heads of the network，将 L2 正则化添加到网络的 t0 和 t1 头\n",
    "    optimizer_Adam = optim.Adam([{'params': net.representation_block.parameters()},\n",
    "                                 {'params': net.t_predictions.parameters()},\n",
    "                                 {'params': net.t0_head.parameters(), 'weight_decay': 0.01},\n",
    "                                 {'params': net.t1_head.parameters(), 'weight_decay': 0.01}], lr=lr)\n",
    "    optimizer_SGD = optim.SGD([{'params': net.representation_block.parameters()},\n",
    "                               {'params': net.t_predictions.parameters()},\n",
    "                               {'params': net.t0_head.parameters(), 'weight_decay': 0.01},\n",
    "                               {'params': net.t1_head.parameters(), 'weight_decay': 0.01}], lr=lr*0.01, momentum=0.9)\n",
    "    scheduler_Adam = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer_Adam, mode='min', factor=0.5, patience=5,\n",
    "                                                          threshold=1e-8, cooldown=0, min_lr=0)\n",
    "    scheduler_SGD = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer_SGD, mode='min', factor=0.5, patience=5,\n",
    "                                                         threshold=0, cooldown=0, min_lr=0)\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    early_stopper = EarlyStopper(patience=2, min_delta=0.)\n",
    "\n",
    "    # Adam training run\n",
    "    for epoch in range(epochs1):\n",
    "\n",
    "        # Train on data\n",
    "        train_loss,val_loss = train(train_loader, net, optimizer_Adam, loss,valid_loader = valid_loader,l1_reg = l1_reg)\n",
    "        \n",
    "        if early_stopper.early_stop(val_loss):             \n",
    "            break\n",
    "\n",
    "        scheduler_Adam.step(val_loss)\n",
    "\n",
    "    #print(f\"Adam loss: train -- {train_loss}, validation -- {val_loss}, epoch {epoch}\")\n",
    "\n",
    "    # SGD training run\n",
    "    \n",
    "    early_stopper = EarlyStopper(patience=40, min_delta=0.)\n",
    "\n",
    "    for epoch in range(epochs2):\n",
    "        # Train on data\n",
    "        train_loss,val_loss = train(train_loader, net, optimizer_SGD, loss,valid_loader = valid_loader,l1_reg = l1_reg)\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):             \n",
    "            break\n",
    "        scheduler_SGD.step(val_loss)\n",
    "        \n",
    "\n",
    "    #print(f\"SGD loss: train --  {train_loss}, validation -- {val_loss},  epoch {epoch}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    #print(\"***************************** elapsed_time is: \", elapsed_time)\n",
    "#对训练集和测试集生成预测，并使用 _split_output 进行拆分，存储在 train_outputs 和 test_outputs 中。\n",
    "    yt_hat_test = net(torch.from_numpy(x_test).float().to(device))\n",
    "    yt_hat_train = net(torch.from_numpy(x_train).float().to(device))\n",
    "\n",
    "    test_outputs += [_split_output(yt_hat_test, t_test, y_test, y_scaler, x_test, test_index)]\n",
    "    train_outputs += [_split_output(yt_hat_train, t_train, y_train, y_scaler, x_train, train_index)]\n",
    "   \n",
    "    train_all_dicts = _split_output(yt_hat_train, t_train, y_train, y_scaler, x_train, train_index)\n",
    "    test_all_dicts = _split_output(yt_hat_test, t_test, y_test, y_scaler, x_test, test_index)\n",
    "#使用 get_estimate 计算因果推断指标（如 psi_n、tmle、ipw_n 等），并将这些结果存储在 train_dict 和 test_dict 中。    \n",
    "    psi_n, psi_tmle, initial_loss, final_loss, g_loss,ipw_n, dr_n = get_estimate(train_all_dicts['q_t0'].reshape(-1, 1), train_all_dicts['q_t1'].reshape(-1, 1), train_all_dicts['g'].reshape(-1, 1), train_all_dicts['t'].reshape(-1, 1), train_all_dicts['y'].reshape(-1, 1), train_all_dicts['index'].reshape(-1, 1), train_all_dicts['eps'].reshape(-1, 1),truncate_level=0.01)\n",
    "\n",
    "    train_dict = {'psi_n':psi_n, 'classification_mse': g_loss,'ipw_n':ipw_n, 'dr_n':dr_n,'regression_loss':regression_loss(torch.tensor(yt_train).to(device),yt_hat_train).cpu().detach(),'BCE':binary_classification_loss(torch.tensor(yt_train).float().to(device),yt_hat_train).cpu().detach().numpy(),'regression_mse':initial_loss,'index':train_all_dicts['index']}\n",
    "    \n",
    "    psi_n, psi_tmle, initial_loss, final_loss, g_loss,ipw_n, dr_n = get_estimate(test_all_dicts['q_t0'].reshape(-1, 1), test_all_dicts['q_t1'].reshape(-1, 1), test_all_dicts['g'].reshape(-1, 1), test_all_dicts['t'].reshape(-1, 1), test_all_dicts['y'].reshape(-1, 1), test_all_dicts['index'].reshape(-1, 1), test_all_dicts['eps'].reshape(-1, 1),truncate_level=0.01)\n",
    "\n",
    "    \n",
    "    test_dict = {'psi_n':psi_n, 'classification_mse': g_loss,'ipw_n':ipw_n, 'dr_n':dr_n,'regression_loss':regression_loss(torch.tensor(yt_test).to(device),yt_hat_test).cpu().detach(),'BCE':binary_classification_loss(torch.tensor(yt_test).float().to(device),yt_hat_test).cpu().detach().numpy(),'regression_mses':initial_loss,'index':test_all_dicts['index']}\n",
    "    return test_outputs, train_outputs, net,train_dict,test_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7b7681-38e2-4c40-be12-895c73694ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing CPU-only mode\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "torch.cuda.is_available = lambda: False\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Forcing CPU-only mode\")\n",
    "def run_KMMsplit(data_base_dir='/Users/asus/Desktop/datasets', output_dir='/Users/asus/Desktop/datasets',\n",
    "                 knob_loss=dragonnet_loss_binarycross, ratio=1., dragon='', lr2=1e-3, l1_reg=1e-3, batchsize2=64):\n",
    "\n",
    "    print(\"the dragon is {}\".format(dragon))\n",
    "    device = torch.device(\"cpu\")\n",
    "    simulation_files = sorted(glob.glob(\"{}/*.csv\".format(data_base_dir)))\n",
    "    \n",
    "    # 初始化列表用于收集所有测试误差\n",
    "    all_err_test = []\n",
    "    all_dr_err_test = []\n",
    "    all_ipw_error_test = []\n",
    "    \n",
    "    final_output = []\n",
    "    for idx, simulation_file in enumerate(simulation_files):\n",
    "        try:\n",
    "            print(f\"\\nProcessing file {idx+1}/{len(simulation_files)}: {os.path.basename(simulation_file)}\")\n",
    "            \n",
    "            # 加载特征和其他变量\n",
    "            x = load_and_format_covariates_ihdp(simulation_file)\n",
    "            t, y, y_cf, mu_0, mu_1 = load_all_other_crap(simulation_file)\n",
    "            \n",
    "            # 超参数设置\n",
    "            batchsize = 64\n",
    "            lr = 1e-3\n",
    "            test_ratio = 0.5\n",
    "            val_split = 0.3\n",
    "            batchsize2 = batchsize2\n",
    "            lr2 = lr2\n",
    "            l1_reg = l1_reg\n",
    "            \n",
    "            # 按照二分类数据 t 列进行分类\n",
    "            # 确保 t 是一维数组并且只用于行索引\n",
    "            x_t0, y_t0 = x[t.ravel() == 0], y[t.ravel() == 0]\n",
    "            x_t1, y_t1 = x[t.ravel() == 1], y[t.ravel() == 1]\n",
    "\n",
    "            # 选择目标索引\n",
    "            target_col_idx = 3\n",
    "            target_idx0 = np.where(x[:, target_col_idx] == 0)[0]  # 源域索引\n",
    "            target_idx1 = np.where(x[:, target_col_idx] == 1)[0]  # 目标域索引\n",
    "\n",
    "            # 获取 x_t0 和 x_t1 的目标索引\n",
    "            target_idx0_t0 = np.where(x_t0[:, target_col_idx] == 0)[0]  # 在 x_t0 中的源域索引\n",
    "            target_idx1_t0 = np.where(x_t0[:, target_col_idx] == 1)[0]  # 在 x_t0 中的目标域索引\n",
    "            target_idx0_t1 = np.where(x_t1[:, target_col_idx] == 0)[0]  # 在 x_t1 中的源域索引\n",
    "            target_idx1_t1 = np.where(x_t1[:, target_col_idx] == 1)[0]  # 在 x_t1 中的目标域索引\n",
    "\n",
    "            # 按索引划分源域和目标域数据\n",
    "            x_t0s, y_t0s = x_t0[target_idx0_t0], y_t0[target_idx0_t0]\n",
    "            x_t0t, y_t0t = x_t0[target_idx1_t0], y_t0[target_idx1_t0]\n",
    "            x_t1s, y_t1s = x_t1[target_idx0_t1], y_t1[target_idx0_t1]\n",
    "            x_t1t, y_t1t = x_t1[target_idx1_t1], y_t1[target_idx1_t1]\n",
    "\n",
    "            # 使用 KMM 进行域适配，分别得到 x_t0s_new 和 x_t1s_new\n",
    "            x_t0s_new = apply_kmm(x_t0s, y_t0s, x_t0t, y_t0t, kernel_type='rbf', gamma=1.0, B=1.0)\n",
    "            x_t1s_new = apply_kmm(x_t1s, y_t1s, x_t1t, y_t1t, kernel_type='rbf', gamma=1.0, B=1.0)\n",
    "\n",
    "            # 合并新源域数据\n",
    "            Xs_new = np.vstack((x_t0s_new, x_t1s_new))\n",
    "\n",
    "            # 使用新的源域数据训练模型\n",
    "            for is_targeted_regularization in [False]:\n",
    "                print(\"Is targeted regularization: {}\".format(is_targeted_regularization))\n",
    "                torch.manual_seed(idx)\n",
    "\n",
    "                if dragon == 'tarnet':\n",
    "                    print('Creating TarNet model')\n",
    "                    net = TarNet(x.shape[1]).to(device)\n",
    "\n",
    "                elif dragon == 'dragonnet':\n",
    "                    print(\"Creating DragonNet model\")\n",
    "                    net = DragonNet(x.shape[1]).to(device)\n",
    "\n",
    "                # 使用更新后的 Xs_new 进行模型训练\n",
    "                _, _, net, _, _ = train_and_predict_dragons(t[target_idx0], y[target_idx0], Xs_new, net, seed=idx,\n",
    "                                                            targeted_regularization=is_targeted_regularization,\n",
    "                                                            knob_loss=knob_loss, ratio=0, dragon=dragon,\n",
    "                                                            val_split=val_split, batch_size=batchsize, lr=lr)\n",
    "\n",
    "                # 保存基模型参数\n",
    "                parm = {}\n",
    "                for name, param in net.named_parameters():\n",
    "                    param.grad = None\n",
    "                    parm[name] = param.detach().cpu()  # 确保在CPU上\n",
    "\n",
    "                # 迁移学习阶段，使用保存的基模型参数\n",
    "                if dragon == 'tarnet':\n",
    "                    print('Creating TarNet_transfer model')\n",
    "                    net = TarNet_transfer(x.shape[1], parm).to(device)\n",
    "\n",
    "                elif dragon == 'dragonnet':\n",
    "                    print(\"Creating DragonNet_transfer model\")\n",
    "                    net = DragonNet_transfer(x.shape[1], parm).to(device)\n",
    "\n",
    "                # 在目标域数据上进行二次训练\n",
    "                test_outputs, train_output, net, train_dict, test_dict = train_and_predict_dragons(\n",
    "                    t[target_idx1], y[target_idx1], x[target_idx1], net, seed=idx,\n",
    "                    targeted_regularization=is_targeted_regularization, knob_loss=knob_loss, ratio=test_ratio,\n",
    "                    dragon=dragon, val_split=val_split, batch_size=batchsize2, lr=lr2, l1_reg=l1_reg)\n",
    "\n",
    "                # 计算误差\n",
    "                for data_dict in [train_dict, test_dict]:\n",
    "                    # 确保索引在范围内\n",
    "                    max_index = len(mu_1) - 1\n",
    "                    valid_indices = [i for i in data_dict['index'] if 0 <= i <= max_index]\n",
    "                    \n",
    "                    if not valid_indices:\n",
    "                        print(f\"Warning: No valid indices in dict, skipping error calculation\")\n",
    "                        continue\n",
    "                        \n",
    "                    truth = (mu_1[valid_indices] - mu_0[valid_indices]).mean()\n",
    "                    \n",
    "                    # 确保预测值存在\n",
    "                    if 'psi_n' not in data_dict or 'dr_n' not in data_dict or 'ipw_n' not in data_dict:\n",
    "                        print(f\"Warning: Missing prediction values in dict, skipping error calculation\")\n",
    "                        continue\n",
    "                        \n",
    "                    data_dict['err'] = abs(truth - data_dict['psi_n']).mean()\n",
    "                    data_dict['dr_err'] = abs(truth - data_dict['dr_n']).mean()\n",
    "                    data_dict['ipw_error'] = abs(truth - data_dict['ipw_n']).mean()\n",
    "                    \n",
    "                    # 如果是测试集，收集误差用于最终统计\n",
    "                    if data_dict is test_dict:\n",
    "                        all_err_test.append(data_dict['err'])\n",
    "                        all_dr_err_test.append(data_dict['dr_err'])\n",
    "                        all_ipw_error_test.append(data_dict['ipw_error'])\n",
    "                \n",
    "                # 将索引转换为列表\n",
    "                test_dict['index'] = test_dict['index'].tolist()\n",
    "                train_dict['index'] = train_dict['index'].tolist()\n",
    "                \n",
    "                # 格式化输出字典\n",
    "                train_dict_formatted = {f'{k}_train': v.item() if 'index' not in k else v for k, v in train_dict.items()}\n",
    "                test_dict_formatted = {f'{k}_test': v.item() if 'index' not in k else v for k, v in test_dict.items()}\n",
    "                \n",
    "                combined_dict = {**train_dict_formatted, **test_dict_formatted}\n",
    "                combined_dict['sim_idx'] = idx\n",
    "                final_output.append(combined_dict)\n",
    "                \n",
    "                # 打印本次结果\n",
    "                print(f\"Simulation {idx} results:\")\n",
    "                print(f\"  Test err: {combined_dict.get('err_test', 'N/A'):.4f}\")\n",
    "                print(f\"  Test dr_err: {combined_dict.get('dr_err_test', 'N/A'):.4f}\")\n",
    "                print(f\"  Test ipw_error: {combined_dict.get('ipw_error_test', 'N/A'):.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {simulation_file}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # 计算所有数据集的误差统计\n",
    "    if all_err_test:\n",
    "        err_mean = np.mean(all_err_test)\n",
    "        err_var = np.var(all_err_test)\n",
    "        dr_err_mean = np.mean(all_dr_err_test)\n",
    "        dr_err_var = np.var(all_dr_err_test)\n",
    "        ipw_err_mean = np.mean(all_ipw_error_test)\n",
    "        ipw_err_var = np.var(all_ipw_error_test)\n",
    "    else:\n",
    "        # 如果没有任何成功的测试，设置默认值\n",
    "        err_mean = err_var = dr_err_mean = dr_err_var = ipw_err_mean = ipw_err_var = -1\n",
    "        print(\"WARNING: No valid test results were collected\")\n",
    "    \n",
    "    # 添加汇总统计到输出\n",
    "    summary = {\n",
    "        'err_mean': float(err_mean),\n",
    "        'err_variance': float(err_var),\n",
    "        'dr_err_mean': float(dr_err_mean),\n",
    "        'dr_err_variance': float(dr_err_var),\n",
    "        'ipw_err_mean': float(ipw_err_mean),\n",
    "        'ipw_err_variance': float(ipw_err_var),\n",
    "        'successful_runs': len(all_err_test)\n",
    "    }\n",
    "    final_output.append({'summary': summary})\n",
    "    \n",
    "    # 保存结果\n",
    "    if not os.path.exists(f'./KMMT0T1params_target{target_col_idx}/'):\n",
    "        os.makedirs(f'./KMMT0T1params_target{target_col_idx}/')\n",
    "    \n",
    "    output_file = f'./KMMT0T1params_target{target_col_idx}/DA2experiments_transfer_{dragon}_{batchsize2}_{l1_reg}_{lr2}.json'\n",
    "    \n",
    "    # 使用自定义编码器保存\n",
    "    class NumpyEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, torch.Tensor):\n",
    "                return obj.detach().cpu().numpy().tolist()\n",
    "            return super(NumpyEncoder, self).default(obj)\n",
    "    \n",
    "    with open(output_file, 'w') as fp:\n",
    "        json.dump(final_output, fp, indent=2, cls=NumpyEncoder)\n",
    "    \n",
    "    # 打印汇总结果\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"Error Summary for All Simulations:\")\n",
    "    print(f\"Successful runs: {len(all_err_test)}/{len(simulation_files)}\")\n",
    "    print(f\"ATE Error: Mean = {err_mean:.4f}, Variance = {err_var:.4f}\")\n",
    "    print(f\"DR Error: Mean = {dr_err_mean:.4f}, Variance = {dr_err_var:.4f}\")\n",
    "    print(f\"IPW Error: Mean = {ipw_err_mean:.4f}, Variance = {ipw_err_var:.4f}\")\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4890ac6d-9b89-4c0c-8f64-30210d0d25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_knob(data_base_dir='/Users/asus/Desktop/datasets/', knob='dragonnet',\n",
    "              output_base_dir='',lr  = 1e-3, l1reg = 1e-4,batchsize = 16):\n",
    "    output_dir = os.path.join(output_base_dir, knob)#扩充output_dir\n",
    "\n",
    "    if knob == 'dragonnet':\n",
    "        run_KMMsplit(data_base_dir=data_base_dir, output_dir=output_dir, dragon='dragonnet' ,lr2  = lr ,l1_reg = l1reg, batchsize2 = batchsize)\n",
    "\n",
    "    if knob == 'tarnet':\n",
    "        run_KKMMsplit(data_base_dir=data_base_dir, output_dir=output_dir, dragon='tarnet',lr2  = lr ,l1_reg = l1reg, batchsize2 = batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2671f46-f984-4146-879f-feff50d5173f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dragon is dragonnet\n",
      "\n",
      "Processing file 1/30: ihdp_shifted_1.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3265e+02 -3.9281e+03  1e+04  7e-02  8e-13\n",
      " 1:  1.1681e+02 -3.2909e+03  9e+03  4e-02  5e-13\n",
      " 2:  1.1906e+02 -9.7288e+02  1e+03  3e-16  2e-13\n",
      " 3:  1.1896e+02  5.1223e+01  7e+01  8e-17  2e-13\n",
      " 4:  1.1745e+02  8.1268e+01  4e+01  7e-17  7e-14\n",
      " 5:  1.1688e+02  1.0950e+02  7e+00  4e-17  2e-12\n",
      " 6:  1.1611e+02  1.1488e+02  1e+00  1e-16  8e-12\n",
      " 7:  1.1590e+02  1.1571e+02  2e-01  3e-16  4e-12\n",
      " 8:  1.1584e+02  1.1582e+02  2e-02  6e-17  4e-12\n",
      " 9:  1.1583e+02  1.1583e+02  7e-04  2e-16  1e-11\n",
      "10:  1.1583e+02  1.1583e+02  2e-05  4e-17  9e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2633e+02 -3.7614e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1081e+02 -3.1434e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1238e+02 -9.2174e+02  1e+03  1e-16  1e-13\n",
      " 3:  1.1231e+02  6.1068e+01  5e+01  6e-17  7e-14\n",
      " 4:  1.1121e+02  8.9586e+01  2e+01  2e-16  2e-14\n",
      " 5:  1.1091e+02  1.0641e+02  4e+00  1e-16  1e-12\n",
      " 6:  1.1055e+02  1.0995e+02  6e-01  2e-16  2e-12\n",
      " 7:  1.1045e+02  1.1038e+02  7e-02  1e-16  2e-12\n",
      " 8:  1.1043e+02  1.1042e+02  5e-03  1e-16  1e-11\n",
      " 9:  1.1043e+02  1.1043e+02  2e-04  2e-16  5e-11\n",
      "10:  1.1043e+02  1.1043e+02  1e-05  8e-16  8e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.525700569152832 and untreated: 0.507388174533844\n",
      "average propensity for treated: 0.525700569152832 and untreated: 0.507388174533844\n",
      "average propensity for treated: 0.525700569152832 and untreated: 0.507388174533844\n",
      "average propensity for treated: 0.525700569152832 and untreated: 0.507388174533844\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5384045839309692 and untreated: 0.5553077459335327\n",
      "average propensity for treated: 0.560924232006073 and untreated: 0.5334448218345642\n",
      "average propensity for treated: 0.560924232006073 and untreated: 0.5334448218345642\n",
      "average propensity for treated: 0.5384045839309692 and untreated: 0.5553077459335327\n",
      "Simulation 0 results:\n",
      "  Test err: 0.6995\n",
      "  Test dr_err: 0.3515\n",
      "  Test ipw_error: 0.7318\n",
      "\n",
      "Processing file 2/30: ihdp_shifted_10.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4264e+02 -4.4666e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.2596e+02 -3.7799e+03  1e+04  4e-02  1e-12\n",
      " 2:  1.2767e+02 -1.1450e+03  1e+03  6e-16  2e-13\n",
      " 3:  1.2760e+02  6.5448e+01  6e+01  6e-17  4e-14\n",
      " 4:  1.2657e+02  9.7148e+01  3e+01  8e-18  3e-14\n",
      " 5:  1.2619e+02  1.2011e+02  6e+00  8e-17  1e-12\n",
      " 6:  1.2569e+02  1.2489e+02  8e-01  2e-16  4e-12\n",
      " 7:  1.2554e+02  1.2545e+02  9e-02  2e-16  3e-12\n",
      " 8:  1.2551e+02  1.2551e+02  8e-03  1e-16  7e-12\n",
      " 9:  1.2551e+02  1.2551e+02  3e-04  1e-16  5e-11\n",
      "10:  1.2551e+02  1.2551e+02  1e-05  1e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1836e+02 -3.2538e+03  1e+04  7e-02  5e-13\n",
      " 1:  1.0356e+02 -2.6828e+03  7e+03  4e-02  3e-13\n",
      " 2:  1.0576e+02 -7.5830e+02  9e+02  9e-17  2e-13\n",
      " 3:  1.0564e+02  3.7289e+01  7e+01  4e-16  1e-13\n",
      " 4:  1.0426e+02  6.1157e+01  4e+01  2e-16  6e-14\n",
      " 5:  1.0370e+02  9.4094e+01  1e+01  2e-16  1e-13\n",
      " 6:  1.0305e+02  9.9155e+01  4e+00  7e-17  5e-13\n",
      " 7:  1.0267e+02  1.0206e+02  6e-01  2e-17  4e-13\n",
      " 8:  1.0254e+02  1.0247e+02  7e-02  1e-16  1e-12\n",
      " 9:  1.0252e+02  1.0251e+02  4e-03  4e-16  4e-12\n",
      "10:  1.0251e+02  1.0251e+02  1e-04  3e-16  1e-11\n",
      "11:  1.0251e+02  1.0251e+02  4e-06  1e-16  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.47794514894485474 and untreated: 0.47082003951072693\n",
      "average propensity for treated: 0.47794514894485474 and untreated: 0.47082003951072693\n",
      "average propensity for treated: 0.47794514894485474 and untreated: 0.47082003951072693\n",
      "average propensity for treated: 0.47794514894485474 and untreated: 0.47082003951072693\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5051717758178711 and untreated: 0.5118119716644287\n",
      "average propensity for treated: 0.5328746438026428 and untreated: 0.4319087266921997\n",
      "average propensity for treated: 0.5328746438026428 and untreated: 0.4319087266921997\n",
      "average propensity for treated: 0.5051717758178711 and untreated: 0.5118119716644287\n",
      "Simulation 1 results:\n",
      "  Test err: 0.3995\n",
      "  Test dr_err: 0.5381\n",
      "  Test ipw_error: 0.8113\n",
      "\n",
      "Processing file 3/30: ihdp_shifted_11.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3902e+02 -4.1698e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.2276e+02 -3.5120e+03  9e+03  4e-02  8e-13\n",
      " 2:  1.2516e+02 -1.0607e+03  1e+03  6e-16  3e-13\n",
      " 3:  1.2506e+02  4.5938e+01  8e+01  4e-16  7e-14\n",
      " 4:  1.2341e+02  7.8657e+01  4e+01  9e-17  7e-14\n",
      " 5:  1.2295e+02  1.1255e+02  1e+01  2e-16  2e-12\n",
      " 6:  1.2219e+02  1.2030e+02  2e+00  1e-16  4e-12\n",
      " 7:  1.2188e+02  1.2164e+02  2e-01  2e-16  2e-12\n",
      " 8:  1.2181e+02  1.2178e+02  3e-02  5e-16  6e-12\n",
      " 9:  1.2180e+02  1.2180e+02  1e-03  1e-16  2e-11\n",
      "10:  1.2180e+02  1.2180e+02  5e-05  7e-16  8e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2243e+02 -3.5280e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.0721e+02 -2.9323e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.0902e+02 -8.4963e+02  1e+03  4e-16  1e-13\n",
      " 3:  1.0894e+02  4.9496e+01  6e+01  2e-16  6e-14\n",
      " 4:  1.0777e+02  7.7385e+01  3e+01  3e-16  2e-14\n",
      " 5:  1.0735e+02  1.0095e+02  6e+00  1e-16  1e-12\n",
      " 6:  1.0676e+02  1.0569e+02  1e+00  2e-16  3e-12\n",
      " 7:  1.0659e+02  1.0643e+02  2e-01  5e-17  3e-12\n",
      " 8:  1.0654e+02  1.0653e+02  2e-02  2e-16  6e-12\n",
      " 9:  1.0654e+02  1.0654e+02  8e-04  6e-16  2e-11\n",
      "10:  1.0654e+02  1.0654e+02  2e-05  2e-16  1e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5272052884101868 and untreated: 0.5119130611419678\n",
      "average propensity for treated: 0.5272052884101868 and untreated: 0.5119130611419678\n",
      "average propensity for treated: 0.5272052884101868 and untreated: 0.5119130611419678\n",
      "average propensity for treated: 0.5272052884101868 and untreated: 0.5119130611419678\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5165200233459473 and untreated: 0.5260096192359924\n",
      "average propensity for treated: 0.5236526131629944 and untreated: 0.5287864804267883\n",
      "average propensity for treated: 0.5236526131629944 and untreated: 0.5287864804267883\n",
      "average propensity for treated: 0.5165200233459473 and untreated: 0.5260096192359924\n",
      "Simulation 2 results:\n",
      "  Test err: 1.0296\n",
      "  Test dr_err: 0.0668\n",
      "  Test ipw_error: 0.7124\n",
      "\n",
      "Processing file 4/30: ihdp_shifted_12.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3492e+02 -4.0240e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.1897e+02 -3.3840e+03  9e+03  4e-02  9e-13\n",
      " 2:  1.2137e+02 -1.0245e+03  1e+03  7e-16  2e-13\n",
      " 3:  1.2127e+02  5.7101e+01  6e+01  6e-16  2e-13\n",
      " 4:  1.1938e+02  8.7166e+01  3e+01  2e-16  4e-14\n",
      " 5:  1.1886e+02  1.1208e+02  7e+00  2e-16  2e-12\n",
      " 6:  1.1821e+02  1.1720e+02  1e+00  3e-16  3e-12\n",
      " 7:  1.1800e+02  1.1787e+02  1e-01  4e-16  3e-12\n",
      " 8:  1.1795e+02  1.1794e+02  1e-02  3e-17  6e-12\n",
      " 9:  1.1795e+02  1.1795e+02  3e-04  2e-16  2e-11\n",
      "10:  1.1795e+02  1.1795e+02  1e-05  3e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2478e+02 -3.6674e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.0938e+02 -3.0557e+03  8e+03  4e-02  9e-13\n",
      " 2:  1.1103e+02 -8.8424e+02  1e+03  2e-16  4e-13\n",
      " 3:  1.1095e+02  4.7689e+01  6e+01  2e-16  4e-14\n",
      " 4:  1.0992e+02  7.6447e+01  3e+01  2e-16  3e-14\n",
      " 5:  1.0962e+02  1.0221e+02  7e+00  2e-16  1e-12\n",
      " 6:  1.0910e+02  1.0804e+02  1e+00  3e-16  4e-12\n",
      " 7:  1.0894e+02  1.0880e+02  1e-01  4e-16  1e-12\n",
      " 8:  1.0891e+02  1.0889e+02  1e-02  5e-16  9e-12\n",
      " 9:  1.0890e+02  1.0890e+02  7e-04  6e-16  2e-11\n",
      "10:  1.0890e+02  1.0890e+02  2e-05  8e-17  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.49592238664627075 and untreated: 0.47237104177474976\n",
      "average propensity for treated: 0.49592238664627075 and untreated: 0.47237104177474976\n",
      "average propensity for treated: 0.49592238664627075 and untreated: 0.47237104177474976\n",
      "average propensity for treated: 0.49592238664627075 and untreated: 0.47237104177474976\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.544007420539856 and untreated: 0.5536435842514038\n",
      "average propensity for treated: 0.5598218441009521 and untreated: 0.5333560705184937\n",
      "average propensity for treated: 0.5598218441009521 and untreated: 0.5333560705184937\n",
      "average propensity for treated: 0.544007420539856 and untreated: 0.5536435842514038\n",
      "Simulation 3 results:\n",
      "  Test err: 0.3473\n",
      "  Test dr_err: 0.7429\n",
      "  Test ipw_error: 1.7280\n",
      "\n",
      "Processing file 5/30: ihdp_shifted_14.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2719e+02 -3.7141e+03  1e+04  7e-02  7e-13\n",
      " 1:  1.1158e+02 -3.0951e+03  8e+03  4e-02  4e-13\n",
      " 2:  1.1317e+02 -8.9304e+02  1e+03  6e-16  2e-13\n",
      " 3:  1.1310e+02  5.6231e+01  6e+01  2e-16  9e-14\n",
      " 4:  1.1209e+02  8.5259e+01  3e+01  7e-17  3e-14\n",
      " 5:  1.1176e+02  1.0609e+02  6e+00  3e-16  1e-12\n",
      " 6:  1.1130e+02  1.1044e+02  9e-01  3e-16  4e-12\n",
      " 7:  1.1117e+02  1.1106e+02  1e-01  2e-16  3e-12\n",
      " 8:  1.1114e+02  1.1113e+02  9e-03  8e-17  7e-12\n",
      " 9:  1.1113e+02  1.1113e+02  4e-04  2e-16  3e-11\n",
      "10:  1.1113e+02  1.1113e+02  2e-05  2e-16  3e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3399e+02 -3.9761e+03  1e+04  7e-02  5e-13\n",
      " 1:  1.1818e+02 -3.3318e+03  9e+03  4e-02  3e-13\n",
      " 2:  1.2079e+02 -9.8128e+02  1e+03  5e-17  2e-13\n",
      " 3:  1.2066e+02  3.4763e+01  9e+01  3e-16  1e-13\n",
      " 4:  1.1887e+02  6.3890e+01  5e+01  2e-16  7e-14\n",
      " 5:  1.1829e+02  1.0615e+02  1e+01  3e-16  3e-13\n",
      " 6:  1.1766e+02  1.1170e+02  6e+00  6e-17  6e-13\n",
      " 7:  1.1715e+02  1.1623e+02  9e-01  2e-16  1e-12\n",
      " 8:  1.1697e+02  1.1685e+02  1e-01  2e-17  2e-12\n",
      " 9:  1.1693e+02  1.1692e+02  9e-03  3e-16  7e-12\n",
      "10:  1.1693e+02  1.1693e+02  3e-04  1e-16  2e-11\n",
      "11:  1.1693e+02  1.1693e+02  8e-06  3e-16  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4872518479824066 and untreated: 0.47914236783981323\n",
      "average propensity for treated: 0.4872518479824066 and untreated: 0.47914236783981323\n",
      "average propensity for treated: 0.4872518479824066 and untreated: 0.47914236783981323\n",
      "average propensity for treated: 0.4872518479824066 and untreated: 0.47914236783981323\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4736694097518921 and untreated: 0.49758049845695496\n",
      "average propensity for treated: 0.5187771916389465 and untreated: 0.46508488059043884\n",
      "average propensity for treated: 0.5187771916389465 and untreated: 0.46508488059043884\n",
      "average propensity for treated: 0.4736694097518921 and untreated: 0.49758049845695496\n",
      "Simulation 4 results:\n",
      "  Test err: 1.6800\n",
      "  Test dr_err: 0.2743\n",
      "  Test ipw_error: 3.0204\n",
      "\n",
      "Processing file 6/30: ihdp_shifted_15.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3791e+02 -4.0480e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.2176e+02 -3.3941e+03  9e+03  4e-02  9e-13\n",
      " 2:  1.2425e+02 -9.9968e+02  1e+03  1e-16  3e-13\n",
      " 3:  1.2413e+02  3.8553e+01  9e+01  3e-16  1e-13\n",
      " 4:  1.2240e+02  6.8158e+01  5e+01  2e-16  1e-13\n",
      " 5:  1.2187e+02  1.1037e+02  1e+01  4e-17  4e-13\n",
      " 6:  1.2124e+02  1.1576e+02  5e+00  1e-16  6e-13\n",
      " 7:  1.2080e+02  1.1997e+02  8e-01  4e-16  1e-12\n",
      " 8:  1.2064e+02  1.2053e+02  1e-01  3e-17  3e-12\n",
      " 9:  1.2061e+02  1.2060e+02  8e-03  4e-16  9e-12\n",
      "10:  1.2060e+02  1.2060e+02  3e-04  3e-16  3e-11\n",
      "11:  1.2060e+02  1.2060e+02  1e-05  4e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2407e+02 -3.6440e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.0877e+02 -3.0381e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1052e+02 -8.8736e+02  1e+03  2e-16  2e-13\n",
      " 3:  1.1044e+02  6.1196e+01  5e+01  3e-16  9e-14\n",
      " 4:  1.0911e+02  8.7918e+01  2e+01  2e-16  3e-14\n",
      " 5:  1.0866e+02  1.0455e+02  4e+00  6e-17  2e-12\n",
      " 6:  1.0828e+02  1.0763e+02  6e-01  1e-16  3e-12\n",
      " 7:  1.0817e+02  1.0809e+02  8e-02  1e-16  2e-12\n",
      " 8:  1.0815e+02  1.0814e+02  8e-03  3e-16  6e-12\n",
      " 9:  1.0814e+02  1.0814e+02  5e-04  1e-16  3e-11\n",
      "10:  1.0814e+02  1.0814e+02  2e-05  1e-16  4e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5148550868034363 and untreated: 0.5068731307983398\n",
      "average propensity for treated: 0.5148550868034363 and untreated: 0.5068731307983398\n",
      "average propensity for treated: 0.5148550868034363 and untreated: 0.5068731307983398\n",
      "average propensity for treated: 0.5148550868034363 and untreated: 0.5068731307983398\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4956446588039398 and untreated: 0.4967961609363556\n",
      "average propensity for treated: 0.5408064126968384 and untreated: 0.4803868234157562\n",
      "average propensity for treated: 0.5408064126968384 and untreated: 0.4803868234157562\n",
      "average propensity for treated: 0.4956446588039398 and untreated: 0.4967961609363556\n",
      "Simulation 5 results:\n",
      "  Test err: 0.9255\n",
      "  Test dr_err: 0.7403\n",
      "  Test ipw_error: 0.3892\n",
      "\n",
      "Processing file 7/30: ihdp_shifted_16.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4206e+02 -4.2683e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.2560e+02 -3.5985e+03  1e+04  4e-02  1e-12\n",
      " 2:  1.2818e+02 -1.0875e+03  1e+03  6e-17  3e-13\n",
      " 3:  1.2807e+02  4.5411e+01  8e+01  4e-16  4e-14\n",
      " 4:  1.2640e+02  7.7325e+01  5e+01  5e-17  6e-14\n",
      " 5:  1.2579e+02  1.1473e+02  1e+01  4e-17  2e-12\n",
      " 6:  1.2486e+02  1.2296e+02  2e+00  5e-16  3e-12\n",
      " 7:  1.2452e+02  1.2425e+02  3e-01  3e-17  2e-12\n",
      " 8:  1.2443e+02  1.2441e+02  2e-02  3e-16  2e-12\n",
      " 9:  1.2442e+02  1.2442e+02  9e-04  1e-16  1e-11\n",
      "10:  1.2442e+02  1.2442e+02  4e-05  2e-16  9e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1964e+02 -3.4356e+03  1e+04  7e-02  8e-13\n",
      " 1:  1.0460e+02 -2.8492e+03  7e+03  4e-02  5e-13\n",
      " 2:  1.0615e+02 -8.1771e+02  9e+02  9e-17  2e-13\n",
      " 3:  1.0608e+02  5.9021e+01  5e+01  3e-16  9e-14\n",
      " 4:  1.0498e+02  8.6890e+01  2e+01  6e-16  2e-14\n",
      " 5:  1.0461e+02  1.0112e+02  3e+00  1e-16  1e-12\n",
      " 6:  1.0427e+02  1.0376e+02  5e-01  7e-17  3e-12\n",
      " 7:  1.0418e+02  1.0412e+02  6e-02  4e-16  4e-12\n",
      " 8:  1.0416e+02  1.0415e+02  5e-03  1e-16  1e-11\n",
      " 9:  1.0416e+02  1.0416e+02  2e-04  3e-16  5e-11\n",
      "10:  1.0416e+02  1.0416e+02  1e-05  5e-16  4e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4412948489189148 and untreated: 0.4336610734462738\n",
      "average propensity for treated: 0.4412948489189148 and untreated: 0.4336610734462738\n",
      "average propensity for treated: 0.4412948489189148 and untreated: 0.4336610734462738\n",
      "average propensity for treated: 0.4412948489189148 and untreated: 0.4336610734462738\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5005028247833252 and untreated: 0.4916006028652191\n",
      "average propensity for treated: 0.48937833309173584 and untreated: 0.4729011058807373\n",
      "average propensity for treated: 0.48937833309173584 and untreated: 0.4729011058807373\n",
      "average propensity for treated: 0.5005028247833252 and untreated: 0.4916006028652191\n",
      "Simulation 6 results:\n",
      "  Test err: 0.9781\n",
      "  Test dr_err: 0.9166\n",
      "  Test ipw_error: 0.3306\n",
      "\n",
      "Processing file 8/30: ihdp_shifted_17.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3189e+02 -3.9039e+03  1e+04  7e-02  3e-12\n",
      " 1:  1.1605e+02 -3.2711e+03  9e+03  4e-02  2e-12\n",
      " 2:  1.1808e+02 -9.7022e+02  1e+03  7e-17  2e-13\n",
      " 3:  1.1798e+02  3.4936e+01  8e+01  2e-16  4e-14\n",
      " 4:  1.1665e+02  6.7732e+01  5e+01  7e-17  5e-14\n",
      " 5:  1.1636e+02  1.0577e+02  1e+01  3e-16  2e-12\n",
      " 6:  1.1568e+02  1.1357e+02  2e+00  3e-16  4e-12\n",
      " 7:  1.1543e+02  1.1514e+02  3e-01  4e-16  9e-13\n",
      " 8:  1.1536e+02  1.1533e+02  3e-02  3e-16  3e-12\n",
      " 9:  1.1535e+02  1.1534e+02  2e-03  4e-17  1e-11\n",
      "10:  1.1534e+02  1.1534e+02  6e-05  4e-17  4e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3131e+02 -3.7849e+03  1e+04  7e-02  8e-13\n",
      " 1:  1.1574e+02 -3.1576e+03  8e+03  4e-02  4e-13\n",
      " 2:  1.1848e+02 -9.1850e+02  1e+03  8e-17  2e-13\n",
      " 3:  1.1834e+02  3.4750e+01  8e+01  1e-16  1e-13\n",
      " 4:  1.1637e+02  6.4770e+01  5e+01  1e-16  8e-14\n",
      " 5:  1.1576e+02  1.0559e+02  1e+01  2e-16  1e-12\n",
      " 6:  1.1502e+02  1.0955e+02  5e+00  3e-16  2e-12\n",
      " 7:  1.1458e+02  1.1365e+02  9e-01  2e-16  5e-13\n",
      " 8:  1.1440e+02  1.1428e+02  1e-01  1e-16  2e-12\n",
      " 9:  1.1437e+02  1.1436e+02  8e-03  5e-17  4e-12\n",
      "10:  1.1436e+02  1.1436e+02  2e-04  2e-16  2e-11\n",
      "11:  1.1436e+02  1.1436e+02  4e-06  3e-16  1e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4964449107646942 and untreated: 0.4663841128349304\n",
      "average propensity for treated: 0.4964449107646942 and untreated: 0.4663841128349304\n",
      "average propensity for treated: 0.4964449107646942 and untreated: 0.4663841128349304\n",
      "average propensity for treated: 0.4964449107646942 and untreated: 0.4663841128349304\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.48883727192878723 and untreated: 0.5291264057159424\n",
      "average propensity for treated: 0.5798973441123962 and untreated: 0.46432578563690186\n",
      "average propensity for treated: 0.5798973441123962 and untreated: 0.46432578563690186\n",
      "average propensity for treated: 0.48883727192878723 and untreated: 0.5291264057159424\n",
      "Simulation 7 results:\n",
      "  Test err: 0.0917\n",
      "  Test dr_err: 0.4819\n",
      "  Test ipw_error: 0.5307\n",
      "\n",
      "Processing file 9/30: ihdp_shifted_18.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3783e+02 -4.0001e+03  1e+04  7e-02  5e-13\n",
      " 1:  1.2164e+02 -3.3491e+03  9e+03  4e-02  3e-13\n",
      " 2:  1.2417e+02 -9.8288e+02  1e+03  4e-16  2e-13\n",
      " 3:  1.2406e+02  5.4643e+01  7e+01  6e-17  2e-13\n",
      " 4:  1.2236e+02  8.4270e+01  4e+01  9e-17  6e-14\n",
      " 5:  1.2173e+02  1.1307e+02  9e+00  3e-16  2e-12\n",
      " 6:  1.2086e+02  1.1944e+02  1e+00  2e-16  4e-12\n",
      " 7:  1.2057e+02  1.2039e+02  2e-01  6e-17  1e-12\n",
      " 8:  1.2051e+02  1.2050e+02  1e-02  2e-16  4e-12\n",
      " 9:  1.2050e+02  1.2050e+02  4e-04  1e-16  1e-11\n",
      "10:  1.2050e+02  1.2050e+02  1e-05  9e-17  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2471e+02 -3.6904e+03  1e+04  7e-02  6e-13\n",
      " 1:  1.0946e+02 -3.0807e+03  8e+03  4e-02  4e-13\n",
      " 2:  1.1134e+02 -9.0233e+02  1e+03  1e-16  2e-13\n",
      " 3:  1.1125e+02  4.6790e+01  6e+01  1e-16  7e-14\n",
      " 4:  1.0982e+02  7.6384e+01  3e+01  9e-17  3e-14\n",
      " 5:  1.0945e+02  1.0236e+02  7e+00  3e-16  1e-12\n",
      " 6:  1.0896e+02  1.0776e+02  1e+00  5e-16  3e-12\n",
      " 7:  1.0880e+02  1.0864e+02  2e-01  1e-16  2e-12\n",
      " 8:  1.0876e+02  1.0875e+02  2e-02  6e-16  6e-12\n",
      " 9:  1.0876e+02  1.0876e+02  1e-03  5e-16  2e-11\n",
      "10:  1.0876e+02  1.0876e+02  5e-05  6e-17  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.46147581934928894 and untreated: 0.45579198002815247\n",
      "average propensity for treated: 0.46147581934928894 and untreated: 0.45579198002815247\n",
      "average propensity for treated: 0.46147581934928894 and untreated: 0.45579198002815247\n",
      "average propensity for treated: 0.46147581934928894 and untreated: 0.45579198002815247\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.462578684091568 and untreated: 0.46164077520370483\n",
      "average propensity for treated: 0.4732550084590912 and untreated: 0.4543112814426422\n",
      "average propensity for treated: 0.4732550084590912 and untreated: 0.4543112814426422\n",
      "average propensity for treated: 0.462578684091568 and untreated: 0.46164077520370483\n",
      "Simulation 8 results:\n",
      "  Test err: 1.9596\n",
      "  Test dr_err: 0.0638\n",
      "  Test ipw_error: 0.8413\n",
      "\n",
      "Processing file 10/30: ihdp_shifted_19.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4113e+02 -4.1939e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.2475e+02 -3.5247e+03  9e+03  4e-02  6e-13\n",
      " 2:  1.2716e+02 -1.0414e+03  1e+03  3e-16  2e-13\n",
      " 3:  1.2706e+02  6.2474e+01  6e+01  8e-17  1e-13\n",
      " 4:  1.2530e+02  9.2294e+01  3e+01  2e-16  6e-14\n",
      " 5:  1.2469e+02  1.1751e+02  7e+00  2e-16  2e-12\n",
      " 6:  1.2393e+02  1.2265e+02  1e+00  1e-16  3e-12\n",
      " 7:  1.2371e+02  1.2353e+02  2e-01  2e-16  3e-12\n",
      " 8:  1.2365e+02  1.2363e+02  2e-02  2e-16  4e-12\n",
      " 9:  1.2364e+02  1.2364e+02  7e-04  5e-17  2e-11\n",
      "10:  1.2364e+02  1.2364e+02  2e-05  2e-17  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1988e+02 -3.5048e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.0475e+02 -2.9156e+03  8e+03  4e-02  6e-13\n",
      " 2:  1.0611e+02 -8.4983e+02  1e+03  2e-16  1e-13\n",
      " 3:  1.0605e+02  6.4498e+01  4e+01  2e-16  6e-14\n",
      " 4:  1.0517e+02  8.9877e+01  2e+01  4e-16  2e-14\n",
      " 5:  1.0489e+02  1.0216e+02  3e+00  2e-16  1e-12\n",
      " 6:  1.0464e+02  1.0429e+02  4e-01  2e-16  4e-12\n",
      " 7:  1.0457e+02  1.0454e+02  4e-02  3e-16  4e-12\n",
      " 8:  1.0456e+02  1.0456e+02  3e-03  3e-16  3e-11\n",
      " 9:  1.0456e+02  1.0456e+02  1e-04  8e-17  9e-11\n",
      "10:  1.0456e+02  1.0456e+02  4e-06  8e-17  1e-09\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5095735788345337 and untreated: 0.4909247159957886\n",
      "average propensity for treated: 0.5095735788345337 and untreated: 0.4909247159957886\n",
      "average propensity for treated: 0.5095735788345337 and untreated: 0.4909247159957886\n",
      "average propensity for treated: 0.5095735788345337 and untreated: 0.4909247159957886\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.496441513299942 and untreated: 0.4898476004600525\n",
      "average propensity for treated: 0.4924241900444031 and untreated: 0.4997981786727905\n",
      "average propensity for treated: 0.4924241900444031 and untreated: 0.4997981786727905\n",
      "average propensity for treated: 0.496441513299942 and untreated: 0.4898476004600525\n",
      "Simulation 9 results:\n",
      "  Test err: 0.4921\n",
      "  Test dr_err: 0.1221\n",
      "  Test ipw_error: 0.1419\n",
      "\n",
      "Processing file 11/30: ihdp_shifted_2.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3069e+02 -3.8564e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1495e+02 -3.2239e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1701e+02 -9.4171e+02  1e+03  1e-16  2e-13\n",
      " 3:  1.1691e+02  5.9499e+01  6e+01  6e-17  1e-13\n",
      " 4:  1.1550e+02  8.9638e+01  3e+01  8e-17  2e-14\n",
      " 5:  1.1494e+02  1.0956e+02  5e+00  1e-16  4e-12\n",
      " 6:  1.1434e+02  1.1352e+02  8e-01  4e-17  5e-12\n",
      " 7:  1.1416e+02  1.1406e+02  1e-01  2e-16  2e-12\n",
      " 8:  1.1412e+02  1.1411e+02  7e-03  9e-16  5e-12\n",
      " 9:  1.1412e+02  1.1412e+02  3e-04  5e-16  2e-11\n",
      "10:  1.1412e+02  1.1412e+02  7e-06  3e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3025e+02 -3.8325e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1452e+02 -3.2080e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1655e+02 -9.5187e+02  1e+03  2e-16  2e-13\n",
      " 3:  1.1646e+02  3.4289e+01  8e+01  8e-17  1e-13\n",
      " 4:  1.1522e+02  6.0986e+01  5e+01  3e-16  6e-14\n",
      " 5:  1.1483e+02  1.0270e+02  1e+01  3e-16  1e-13\n",
      " 6:  1.1411e+02  1.1057e+02  4e+00  3e-16  3e-13\n",
      " 7:  1.1384e+02  1.1335e+02  5e-01  2e-16  7e-13\n",
      " 8:  1.1375e+02  1.1369e+02  6e-02  1e-16  4e-12\n",
      " 9:  1.1373e+02  1.1373e+02  4e-03  4e-16  9e-12\n",
      "10:  1.1373e+02  1.1373e+02  2e-04  3e-17  4e-11\n",
      "11:  1.1373e+02  1.1373e+02  6e-06  3e-16  5e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4816180467605591 and untreated: 0.4699186384677887\n",
      "average propensity for treated: 0.4816180467605591 and untreated: 0.4699186384677887\n",
      "average propensity for treated: 0.4816180467605591 and untreated: 0.4699186384677887\n",
      "average propensity for treated: 0.4816180467605591 and untreated: 0.4699186384677887\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4874618351459503 and untreated: 0.49974045157432556\n",
      "average propensity for treated: 0.5028595924377441 and untreated: 0.4765160083770752\n",
      "average propensity for treated: 0.5028595924377441 and untreated: 0.4765160083770752\n",
      "average propensity for treated: 0.4874618351459503 and untreated: 0.49974045157432556\n",
      "Simulation 10 results:\n",
      "  Test err: 0.6457\n",
      "  Test dr_err: 0.1800\n",
      "  Test ipw_error: 0.1932\n",
      "\n",
      "Processing file 12/30: ihdp_shifted_20.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2976e+02 -3.8324e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1396e+02 -3.2061e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1557e+02 -9.4418e+02  1e+03  4e-16  2e-13\n",
      " 3:  1.1550e+02  7.3744e+01  4e+01  1e-16  9e-14\n",
      " 4:  1.1436e+02  1.0091e+02  1e+01  2e-16  2e-14\n",
      " 5:  1.1392e+02  1.1156e+02  2e+00  6e-17  2e-12\n",
      " 6:  1.1362e+02  1.1331e+02  3e-01  1e-16  4e-12\n",
      " 7:  1.1355e+02  1.1351e+02  3e-02  9e-17  1e-11\n",
      " 8:  1.1353e+02  1.1353e+02  2e-03  3e-16  2e-11\n",
      " 9:  1.1353e+02  1.1353e+02  1e-04  6e-17  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3087e+02 -3.8565e+03  1e+04  7e-02  8e-13\n",
      " 1:  1.1506e+02 -3.2199e+03  8e+03  4e-02  5e-13\n",
      " 2:  1.1697e+02 -9.2937e+02  1e+03  1e-16  2e-13\n",
      " 3:  1.1688e+02  5.8980e+01  6e+01  1e-16  9e-14\n",
      " 4:  1.1555e+02  8.7703e+01  3e+01  1e-17  4e-14\n",
      " 5:  1.1506e+02  1.0917e+02  6e+00  3e-16  1e-12\n",
      " 6:  1.1452e+02  1.1351e+02  1e+00  4e-16  3e-12\n",
      " 7:  1.1435e+02  1.1422e+02  1e-01  7e-17  3e-12\n",
      " 8:  1.1430e+02  1.1430e+02  9e-03  5e-17  8e-12\n",
      " 9:  1.1430e+02  1.1430e+02  3e-04  2e-16  2e-11\n",
      "10:  1.1430e+02  1.1430e+02  9e-06  6e-17  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4767281711101532 and untreated: 0.4701484441757202\n",
      "average propensity for treated: 0.4767281711101532 and untreated: 0.4701484441757202\n",
      "average propensity for treated: 0.4767281711101532 and untreated: 0.4701484441757202\n",
      "average propensity for treated: 0.4767281711101532 and untreated: 0.4701484441757202\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.46003371477127075 and untreated: 0.5097289085388184\n",
      "average propensity for treated: 0.48854416608810425 and untreated: 0.4723338484764099\n",
      "average propensity for treated: 0.48854416608810425 and untreated: 0.4723338484764099\n",
      "average propensity for treated: 0.46003371477127075 and untreated: 0.5097289085388184\n",
      "Simulation 11 results:\n",
      "  Test err: 1.3369\n",
      "  Test dr_err: 0.7242\n",
      "  Test ipw_error: 1.5656\n",
      "\n",
      "Processing file 13/30: ihdp_shifted_21.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2040e+02 -3.4589e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.0532e+02 -2.8717e+03  7e+03  4e-02  6e-13\n",
      " 2:  1.0709e+02 -8.3165e+02  9e+02  1e-17  5e-13\n",
      " 3:  1.0700e+02  4.9448e+01  6e+01  2e-16  8e-14\n",
      " 4:  1.0582e+02  7.6933e+01  3e+01  4e-16  2e-14\n",
      " 5:  1.0541e+02  9.9655e+01  6e+00  5e-16  2e-12\n",
      " 6:  1.0489e+02  1.0400e+02  9e-01  2e-16  2e-12\n",
      " 7:  1.0474e+02  1.0463e+02  1e-01  3e-16  2e-12\n",
      " 8:  1.0470e+02  1.0469e+02  9e-03  5e-16  7e-12\n",
      " 9:  1.0470e+02  1.0469e+02  4e-04  1e-16  3e-11\n",
      "10:  1.0469e+02  1.0469e+02  1e-05  4e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4155e+02 -4.2427e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.2518e+02 -3.5783e+03  1e+04  4e-02  6e-13\n",
      " 2:  1.2768e+02 -1.0860e+03  1e+03  2e-16  2e-13\n",
      " 3:  1.2757e+02  5.4431e+01  7e+01  3e-16  4e-14\n",
      " 4:  1.2589e+02  8.6450e+01  4e+01  8e-17  4e-14\n",
      " 5:  1.2527e+02  1.1742e+02  8e+00  9e-17  2e-12\n",
      " 6:  1.2445e+02  1.2306e+02  1e+00  7e-17  6e-12\n",
      " 7:  1.2418e+02  1.2400e+02  2e-01  4e-16  2e-12\n",
      " 8:  1.2412e+02  1.2411e+02  2e-02  4e-16  4e-12\n",
      " 9:  1.2411e+02  1.2411e+02  6e-04  6e-16  1e-11\n",
      "10:  1.2411e+02  1.2411e+02  1e-05  2e-16  1e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5002485513687134 and untreated: 0.4924188256263733\n",
      "average propensity for treated: 0.5002485513687134 and untreated: 0.4924188256263733\n",
      "average propensity for treated: 0.5002485513687134 and untreated: 0.4924188256263733\n",
      "average propensity for treated: 0.5002485513687134 and untreated: 0.4924188256263733\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.40950390696525574 and untreated: 0.4236275255680084\n",
      "average propensity for treated: 0.42530354857444763 and untreated: 0.4127269983291626\n",
      "average propensity for treated: 0.42530354857444763 and untreated: 0.4127269983291626\n",
      "average propensity for treated: 0.40950390696525574 and untreated: 0.4236275255680084\n",
      "Simulation 12 results:\n",
      "  Test err: 0.6109\n",
      "  Test dr_err: 0.0547\n",
      "  Test ipw_error: 1.2965\n",
      "\n",
      "Processing file 14/30: ihdp_shifted_22.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4539e+02 -4.3909e+03  1e+04  7e-02  8e-13\n",
      " 1:  1.2870e+02 -3.7028e+03  1e+04  4e-02  5e-13\n",
      " 2:  1.3098e+02 -1.1021e+03  1e+03  2e-16  2e-13\n",
      " 3:  1.3089e+02  5.8611e+01  7e+01  1e-16  4e-14\n",
      " 4:  1.2931e+02  9.0806e+01  4e+01  2e-16  2e-14\n",
      " 5:  1.2880e+02  1.2026e+02  9e+00  1e-16  1e-12\n",
      " 6:  1.2801e+02  1.2670e+02  1e+00  1e-16  1e-11\n",
      " 7:  1.2777e+02  1.2759e+02  2e-01  1e-16  4e-12\n",
      " 8:  1.2771e+02  1.2769e+02  2e-02  2e-16  1e-11\n",
      " 9:  1.2770e+02  1.2770e+02  1e-03  2e-16  1e-11\n",
      "10:  1.2770e+02  1.2770e+02  4e-05  3e-17  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1728e+02 -3.3218e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.0238e+02 -2.7471e+03  7e+03  4e-02  1e-12\n",
      " 2:  1.0393e+02 -7.8373e+02  9e+02  1e-16  2e-13\n",
      " 3:  1.0386e+02  6.4587e+01  4e+01  2e-16  4e-14\n",
      " 4:  1.0273e+02  8.8688e+01  1e+01  3e-16  3e-14\n",
      " 5:  1.0231e+02  9.9908e+01  2e+00  1e-16  2e-12\n",
      " 6:  1.0202e+02  1.0167e+02  4e-01  7e-17  5e-12\n",
      " 7:  1.0194e+02  1.0190e+02  4e-02  1e-16  5e-12\n",
      " 8:  1.0193e+02  1.0192e+02  2e-03  9e-18  2e-11\n",
      " 9:  1.0192e+02  1.0192e+02  7e-05  4e-16  6e-11\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4316001832485199 and untreated: 0.41422975063323975\n",
      "average propensity for treated: 0.4316001832485199 and untreated: 0.41422975063323975\n",
      "average propensity for treated: 0.4316001832485199 and untreated: 0.41422975063323975\n",
      "average propensity for treated: 0.4316001832485199 and untreated: 0.41422975063323975\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.3999819755554199 and untreated: 0.38775283098220825\n",
      "average propensity for treated: 0.44871774315834045 and untreated: 0.40085330605506897\n",
      "average propensity for treated: 0.44871774315834045 and untreated: 0.40085330605506897\n",
      "average propensity for treated: 0.3999819755554199 and untreated: 0.38775283098220825\n",
      "Simulation 13 results:\n",
      "  Test err: 1.2019\n",
      "  Test dr_err: 1.9162\n",
      "  Test ipw_error: 2.1538\n",
      "\n",
      "Processing file 15/30: ihdp_shifted_23.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3495e+02 -4.0004e+03  1e+04  7e-02  6e-13\n",
      " 1:  1.1883e+02 -3.3562e+03  9e+03  4e-02  3e-13\n",
      " 2:  1.2089e+02 -9.9826e+02  1e+03  6e-16  2e-13\n",
      " 3:  1.2080e+02  5.7693e+01  6e+01  3e-16  8e-14\n",
      " 4:  1.1946e+02  8.9212e+01  3e+01  2e-16  2e-14\n",
      " 5:  1.1895e+02  1.1250e+02  6e+00  3e-16  2e-12\n",
      " 6:  1.1833e+02  1.1720e+02  1e+00  4e-16  4e-12\n",
      " 7:  1.1814e+02  1.1799e+02  2e-01  2e-16  3e-12\n",
      " 8:  1.1809e+02  1.1808e+02  1e-02  1e-17  4e-12\n",
      " 9:  1.1809e+02  1.1808e+02  6e-04  2e-16  2e-11\n",
      "10:  1.1809e+02  1.1809e+02  2e-05  5e-16  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2795e+02 -3.6905e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1247e+02 -3.0789e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1473e+02 -9.0488e+02  1e+03  7e-17  2e-13\n",
      " 3:  1.1462e+02  4.2484e+01  7e+01  2e-16  4e-14\n",
      " 4:  1.1297e+02  7.3030e+01  4e+01  7e-16  6e-14\n",
      " 5:  1.1253e+02  1.0452e+02  8e+00  5e-17  1e-12\n",
      " 6:  1.1178e+02  1.1029e+02  1e+00  1e-16  7e-12\n",
      " 7:  1.1158e+02  1.1136e+02  2e-01  2e-16  2e-12\n",
      " 8:  1.1152e+02  1.1150e+02  2e-02  1e-16  3e-12\n",
      " 9:  1.1151e+02  1.1151e+02  8e-04  1e-16  9e-12\n",
      "10:  1.1151e+02  1.1151e+02  3e-05  6e-16  1e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5053349733352661 and untreated: 0.498114675283432\n",
      "average propensity for treated: 0.5053349733352661 and untreated: 0.498114675283432\n",
      "average propensity for treated: 0.5053349733352661 and untreated: 0.498114675283432\n",
      "average propensity for treated: 0.5053349733352661 and untreated: 0.498114675283432\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5694208741188049 and untreated: 0.5220486521720886\n",
      "average propensity for treated: 0.5138807892799377 and untreated: 0.450444757938385\n",
      "average propensity for treated: 0.5138807892799377 and untreated: 0.450444757938385\n",
      "average propensity for treated: 0.5694208741188049 and untreated: 0.5220486521720886\n",
      "Simulation 14 results:\n",
      "  Test err: 0.6066\n",
      "  Test dr_err: 0.8126\n",
      "  Test ipw_error: 2.8937\n",
      "\n",
      "Processing file 16/30: ihdp_shifted_24.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2201e+02 -3.6439e+03  1e+04  7e-02  6e-13\n",
      " 1:  1.0677e+02 -3.0349e+03  8e+03  4e-02  4e-13\n",
      " 2:  1.0804e+02 -8.7199e+02  1e+03  9e-17  1e-13\n",
      " 3:  1.0799e+02  6.9996e+01  4e+01  2e-16  4e-14\n",
      " 4:  1.0718e+02  9.4845e+01  1e+01  4e-16  2e-14\n",
      " 5:  1.0687e+02  1.0472e+02  2e+00  1e-16  1e-12\n",
      " 6:  1.0665e+02  1.0639e+02  3e-01  1e-16  3e-12\n",
      " 7:  1.0661e+02  1.0658e+02  3e-02  2e-16  8e-12\n",
      " 8:  1.0660e+02  1.0660e+02  2e-03  4e-16  2e-11\n",
      " 9:  1.0660e+02  1.0660e+02  1e-04  1e-16  8e-11\n",
      "10:  1.0660e+02  1.0660e+02  7e-06  2e-16  6e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3938e+02 -4.0484e+03  1e+04  7e-02  8e-13\n",
      " 1:  1.2323e+02 -3.3940e+03  9e+03  4e-02  5e-13\n",
      " 2:  1.2625e+02 -1.0044e+03  1e+03  2e-16  3e-13\n",
      " 3:  1.2611e+02  4.3637e+01  8e+01  3e-16  9e-14\n",
      " 4:  1.2399e+02  7.4244e+01  5e+01  4e-16  7e-14\n",
      " 5:  1.2325e+02  1.1212e+02  1e+01  2e-16  2e-12\n",
      " 6:  1.2215e+02  1.2007e+02  2e+00  2e-16  4e-12\n",
      " 7:  1.2180e+02  1.2146e+02  3e-01  6e-16  2e-12\n",
      " 8:  1.2171e+02  1.2167e+02  3e-02  8e-16  3e-12\n",
      " 9:  1.2169e+02  1.2169e+02  2e-03  5e-16  9e-12\n",
      "10:  1.2169e+02  1.2169e+02  4e-05  1e-16  5e-11\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5404207706451416 and untreated: 0.5327633619308472\n",
      "average propensity for treated: 0.5404207706451416 and untreated: 0.5327633619308472\n",
      "average propensity for treated: 0.5404207706451416 and untreated: 0.5327633619308472\n",
      "average propensity for treated: 0.5404207706451416 and untreated: 0.5327633619308472\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5681760907173157 and untreated: 0.5385380983352661\n",
      "average propensity for treated: 0.5654289722442627 and untreated: 0.5717960000038147\n",
      "average propensity for treated: 0.5654289722442627 and untreated: 0.5717960000038147\n",
      "average propensity for treated: 0.5681760907173157 and untreated: 0.5385380983352661\n",
      "Simulation 15 results:\n",
      "  Test err: 0.0875\n",
      "  Test dr_err: 0.5499\n",
      "  Test ipw_error: 0.4619\n",
      "\n",
      "Processing file 17/30: ihdp_shifted_25.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2657e+02 -3.6902e+03  1e+04  7e-02  8e-13\n",
      " 1:  1.1113e+02 -3.0733e+03  8e+03  4e-02  5e-13\n",
      " 2:  1.1291e+02 -8.8356e+02  1e+03  5e-17  3e-13\n",
      " 3:  1.1282e+02  5.3086e+01  6e+01  3e-16  8e-14\n",
      " 4:  1.1163e+02  8.2920e+01  3e+01  4e-17  6e-14\n",
      " 5:  1.1121e+02  1.0534e+02  6e+00  3e-16  2e-12\n",
      " 6:  1.1068e+02  1.0978e+02  9e-01  6e-16  5e-12\n",
      " 7:  1.1052e+02  1.1041e+02  1e-01  6e-17  1e-12\n",
      " 8:  1.1049e+02  1.1048e+02  9e-03  3e-16  8e-12\n",
      " 9:  1.1048e+02  1.1048e+02  4e-04  1e-16  5e-11\n",
      "10:  1.1048e+02  1.1048e+02  1e-05  1e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3442e+02 -4.0003e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1848e+02 -3.3513e+03  9e+03  4e-02  1e-12\n",
      " 2:  1.2079e+02 -9.8127e+02  1e+03  4e-16  3e-13\n",
      " 3:  1.2069e+02  5.0056e+01  7e+01  4e-16  5e-14\n",
      " 4:  1.1902e+02  7.9399e+01  4e+01  2e-16  4e-14\n",
      " 5:  1.1846e+02  1.0999e+02  8e+00  2e-16  2e-12\n",
      " 6:  1.1770e+02  1.1630e+02  1e+00  2e-16  4e-12\n",
      " 7:  1.1748e+02  1.1726e+02  2e-01  3e-16  1e-12\n",
      " 8:  1.1742e+02  1.1739e+02  2e-02  1e-16  5e-12\n",
      " 9:  1.1741e+02  1.1740e+02  1e-03  1e-16  2e-11\n",
      "10:  1.1741e+02  1.1741e+02  4e-05  6e-17  7e-11\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.47362029552459717 and untreated: 0.4712386429309845\n",
      "average propensity for treated: 0.47362029552459717 and untreated: 0.4712386429309845\n",
      "average propensity for treated: 0.47362029552459717 and untreated: 0.4712386429309845\n",
      "average propensity for treated: 0.47362029552459717 and untreated: 0.4712386429309845\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.47814613580703735 and untreated: 0.45733439922332764\n",
      "average propensity for treated: 0.49995407462120056 and untreated: 0.44452783465385437\n",
      "average propensity for treated: 0.49995407462120056 and untreated: 0.44452783465385437\n",
      "average propensity for treated: 0.47814613580703735 and untreated: 0.45733439922332764\n",
      "Simulation 16 results:\n",
      "  Test err: 0.7254\n",
      "  Test dr_err: 0.7287\n",
      "  Test ipw_error: 1.2029\n",
      "\n",
      "Processing file 18/30: ihdp_shifted_26.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2710e+02 -3.6913e+03  1e+04  7e-02  4e-12\n",
      " 1:  1.1153e+02 -3.0754e+03  8e+03  4e-02  2e-12\n",
      " 2:  1.1344e+02 -8.9196e+02  1e+03  1e-16  2e-13\n",
      " 3:  1.1336e+02  5.6593e+01  6e+01  3e-17  2e-13\n",
      " 4:  1.1206e+02  8.5213e+01  3e+01  2e-16  4e-14\n",
      " 5:  1.1156e+02  1.0620e+02  5e+00  1e-16  2e-12\n",
      " 6:  1.1101e+02  1.1021e+02  8e-01  2e-16  3e-12\n",
      " 7:  1.1085e+02  1.1075e+02  1e-01  4e-16  3e-12\n",
      " 8:  1.1082e+02  1.1081e+02  8e-03  2e-16  6e-12\n",
      " 9:  1.1081e+02  1.1081e+02  3e-04  1e-16  2e-11\n",
      "10:  1.1081e+02  1.1081e+02  1e-05  4e-17  4e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3501e+02 -3.9994e+03  1e+04  7e-02  9e-13\n",
      " 1:  1.1904e+02 -3.3544e+03  9e+03  4e-02  6e-13\n",
      " 2:  1.2124e+02 -9.9224e+02  1e+03  3e-16  2e-13\n",
      " 3:  1.2114e+02  5.4485e+01  7e+01  7e-16  1e-13\n",
      " 4:  1.1955e+02  8.5079e+01  3e+01  1e-16  5e-14\n",
      " 5:  1.1902e+02  1.1180e+02  7e+00  4e-16  2e-12\n",
      " 6:  1.1838e+02  1.1714e+02  1e+00  3e-16  3e-12\n",
      " 7:  1.1817e+02  1.1799e+02  2e-01  4e-16  4e-12\n",
      " 8:  1.1812e+02  1.1810e+02  2e-02  3e-16  4e-12\n",
      " 9:  1.1811e+02  1.1811e+02  8e-04  1e-16  2e-11\n",
      "10:  1.1811e+02  1.1811e+02  3e-05  1e-16  8e-11\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4907354712486267 and untreated: 0.48322537541389465\n",
      "average propensity for treated: 0.4907354712486267 and untreated: 0.48322537541389465\n",
      "average propensity for treated: 0.4907354712486267 and untreated: 0.48322537541389465\n",
      "average propensity for treated: 0.4907354712486267 and untreated: 0.48322537541389465\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4221039414405823 and untreated: 0.40586861968040466\n",
      "average propensity for treated: 0.45087310671806335 and untreated: 0.38083770871162415\n",
      "average propensity for treated: 0.45087310671806335 and untreated: 0.38083770871162415\n",
      "average propensity for treated: 0.4221039414405823 and untreated: 0.40586861968040466\n",
      "Simulation 17 results:\n",
      "  Test err: 0.4607\n",
      "  Test dr_err: 2.6638\n",
      "  Test ipw_error: 6.1540\n",
      "\n",
      "Processing file 19/30: ihdp_shifted_27.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2675e+02 -3.6672e+03  1e+04  7e-02  7e-13\n",
      " 1:  1.1122e+02 -3.0564e+03  8e+03  4e-02  5e-13\n",
      " 2:  1.1304e+02 -8.9108e+02  1e+03  2e-16  1e-13\n",
      " 3:  1.1296e+02  6.0509e+01  5e+01  1e-16  1e-13\n",
      " 4:  1.1164e+02  8.8363e+01  2e+01  5e-16  2e-14\n",
      " 5:  1.1119e+02  1.0671e+02  4e+00  4e-16  2e-12\n",
      " 6:  1.1072e+02  1.1002e+02  7e-01  7e-17  5e-12\n",
      " 7:  1.1059e+02  1.1051e+02  8e-02  6e-16  3e-12\n",
      " 8:  1.1056e+02  1.1055e+02  6e-03  9e-17  1e-11\n",
      " 9:  1.1056e+02  1.1056e+02  3e-04  2e-16  2e-11\n",
      "10:  1.1056e+02  1.1056e+02  1e-05  1e-16  5e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3469e+02 -4.0243e+03  1e+04  7e-02  5e-13\n",
      " 1:  1.1867e+02 -3.3767e+03  9e+03  4e-02  3e-13\n",
      " 2:  1.2078e+02 -9.9969e+02  1e+03  2e-16  2e-13\n",
      " 3:  1.2069e+02  6.1387e+01  6e+01  9e-17  1e-13\n",
      " 4:  1.1918e+02  9.1492e+01  3e+01  2e-16  3e-14\n",
      " 5:  1.1859e+02  1.1311e+02  5e+00  3e-17  2e-12\n",
      " 6:  1.1803e+02  1.1705e+02  1e+00  1e-16  7e-12\n",
      " 7:  1.1786e+02  1.1772e+02  1e-01  9e-17  3e-12\n",
      " 8:  1.1782e+02  1.1780e+02  1e-02  4e-16  9e-12\n",
      " 9:  1.1781e+02  1.1781e+02  5e-04  4e-16  4e-11\n",
      "10:  1.1781e+02  1.1781e+02  1e-05  9e-17  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.556195080280304 and untreated: 0.5417534112930298\n",
      "average propensity for treated: 0.556195080280304 and untreated: 0.5417534112930298\n",
      "average propensity for treated: 0.556195080280304 and untreated: 0.5417534112930298\n",
      "average propensity for treated: 0.556195080280304 and untreated: 0.5417534112930298\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.41025272011756897 and untreated: 0.44478684663772583\n",
      "average propensity for treated: 0.4743654131889343 and untreated: 0.3742557764053345\n",
      "average propensity for treated: 0.4743654131889343 and untreated: 0.3742557764053345\n",
      "average propensity for treated: 0.41025272011756897 and untreated: 0.44478684663772583\n",
      "Simulation 18 results:\n",
      "  Test err: 0.5695\n",
      "  Test dr_err: 1.4633\n",
      "  Test ipw_error: 2.7276\n",
      "\n",
      "Processing file 20/30: ihdp_shifted_28.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3850e+02 -4.0967e+03  1e+04  7e-02  6e-13\n",
      " 1:  1.2227e+02 -3.4469e+03  9e+03  4e-02  4e-13\n",
      " 2:  1.2475e+02 -1.0437e+03  1e+03  2e-16  2e-13\n",
      " 3:  1.2464e+02  4.9179e+01  8e+01  1e-16  3e-13\n",
      " 4:  1.2294e+02  8.1217e+01  4e+01  5e-16  4e-14\n",
      " 5:  1.2240e+02  1.1308e+02  9e+00  3e-16  1e-12\n",
      " 6:  1.2159e+02  1.2010e+02  1e+00  2e-16  3e-12\n",
      " 7:  1.2131e+02  1.2111e+02  2e-01  3e-16  2e-12\n",
      " 8:  1.2125e+02  1.2123e+02  2e-02  1e-16  6e-12\n",
      " 9:  1.2124e+02  1.2124e+02  6e-04  9e-17  2e-11\n",
      "10:  1.2124e+02  1.2124e+02  2e-05  2e-16  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2318e+02 -3.5974e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.0787e+02 -2.9971e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.0949e+02 -8.7620e+02  1e+03  5e-17  2e-13\n",
      " 3:  1.0942e+02  6.3807e+01  5e+01  2e-16  6e-14\n",
      " 4:  1.0828e+02  9.0400e+01  2e+01  7e-17  3e-14\n",
      " 5:  1.0788e+02  1.0461e+02  3e+00  2e-16  2e-12\n",
      " 6:  1.0755e+02  1.0702e+02  5e-01  1e-16  4e-12\n",
      " 7:  1.0746e+02  1.0740e+02  6e-02  3e-16  4e-12\n",
      " 8:  1.0744e+02  1.0743e+02  5e-03  3e-16  2e-11\n",
      " 9:  1.0744e+02  1.0743e+02  2e-04  1e-17  4e-11\n",
      "10:  1.0743e+02  1.0743e+02  8e-06  2e-16  4e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5492936372756958 and untreated: 0.5270892977714539\n",
      "average propensity for treated: 0.5492936372756958 and untreated: 0.5270892977714539\n",
      "average propensity for treated: 0.5492936372756958 and untreated: 0.5270892977714539\n",
      "average propensity for treated: 0.5492936372756958 and untreated: 0.5270892977714539\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5637573003768921 and untreated: 0.5743619799613953\n",
      "average propensity for treated: 0.5753227472305298 and untreated: 0.5134004950523376\n",
      "average propensity for treated: 0.5753227472305298 and untreated: 0.5134004950523376\n",
      "average propensity for treated: 0.5637573003768921 and untreated: 0.5743619799613953\n",
      "Simulation 19 results:\n",
      "  Test err: 0.4113\n",
      "  Test dr_err: 0.4433\n",
      "  Test ipw_error: 0.7834\n",
      "\n",
      "Processing file 21/30: ihdp_shifted_30.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3336e+02 -3.9043e+03  1e+04  7e-02  6e-13\n",
      " 1:  1.1739e+02 -3.2657e+03  8e+03  4e-02  4e-13\n",
      " 2:  1.1953e+02 -9.5687e+02  1e+03  8e-17  2e-13\n",
      " 3:  1.1944e+02  5.1290e+01  7e+01  4e-16  5e-14\n",
      " 4:  1.1795e+02  8.1503e+01  4e+01  4e-17  4e-14\n",
      " 5:  1.1748e+02  1.0917e+02  8e+00  3e-16  1e-12\n",
      " 6:  1.1680e+02  1.1535e+02  1e+00  1e-16  3e-12\n",
      " 7:  1.1657e+02  1.1636e+02  2e-01  3e-16  2e-12\n",
      " 8:  1.1651e+02  1.1649e+02  2e-02  4e-16  4e-12\n",
      " 9:  1.1650e+02  1.1650e+02  6e-04  3e-16  2e-11\n",
      "10:  1.1650e+02  1.1650e+02  1e-05  2e-16  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2897e+02 -3.7848e+03  1e+04  7e-02  5e-12\n",
      " 1:  1.1334e+02 -3.1640e+03  8e+03  4e-02  3e-12\n",
      " 2:  1.1526e+02 -9.3220e+02  1e+03  6e-17  2e-13\n",
      " 3:  1.1518e+02  5.7508e+01  6e+01  3e-16  7e-14\n",
      " 4:  1.1383e+02  8.5948e+01  3e+01  2e-16  2e-14\n",
      " 5:  1.1339e+02  1.0751e+02  6e+00  1e-16  1e-12\n",
      " 6:  1.1283e+02  1.1193e+02  9e-01  8e-17  4e-12\n",
      " 7:  1.1266e+02  1.1254e+02  1e-01  4e-16  3e-12\n",
      " 8:  1.1262e+02  1.1261e+02  1e-02  3e-16  7e-12\n",
      " 9:  1.1261e+02  1.1261e+02  5e-04  2e-16  3e-11\n",
      "10:  1.1261e+02  1.1261e+02  2e-05  1e-16  1e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4983164668083191 and untreated: 0.4929521679878235\n",
      "average propensity for treated: 0.4983164668083191 and untreated: 0.4929521679878235\n",
      "average propensity for treated: 0.4983164668083191 and untreated: 0.4929521679878235\n",
      "average propensity for treated: 0.4983164668083191 and untreated: 0.4929521679878235\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4483204782009125 and untreated: 0.45506325364112854\n",
      "average propensity for treated: 0.4503803849220276 and untreated: 0.43634939193725586\n",
      "average propensity for treated: 0.4503803849220276 and untreated: 0.43634939193725586\n",
      "average propensity for treated: 0.4483204782009125 and untreated: 0.45506325364112854\n",
      "Simulation 20 results:\n",
      "  Test err: 0.4019\n",
      "  Test dr_err: 0.1354\n",
      "  Test ipw_error: 0.2407\n",
      "\n",
      "Processing file 22/30: ihdp_shifted_31.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3551e+02 -4.0968e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1934e+02 -3.4501e+03  9e+03  4e-02  1e-12\n",
      " 2:  1.2119e+02 -1.0459e+03  1e+03  3e-16  2e-13\n",
      " 3:  1.2111e+02  7.4444e+01  5e+01  3e-16  4e-14\n",
      " 4:  1.1979e+02  1.0392e+02  2e+01  3e-16  3e-14\n",
      " 5:  1.1930e+02  1.1636e+02  3e+00  3e-16  2e-12\n",
      " 6:  1.1893e+02  1.1855e+02  4e-01  7e-17  7e-12\n",
      " 7:  1.1883e+02  1.1879e+02  4e-02  2e-16  9e-12\n",
      " 8:  1.1882e+02  1.1881e+02  2e-03  5e-17  2e-11\n",
      " 9:  1.1881e+02  1.1881e+02  8e-05  4e-17  8e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2557e+02 -3.5972e+03  1e+04  7e-02  6e-13\n",
      " 1:  1.1020e+02 -2.9913e+03  8e+03  4e-02  3e-13\n",
      " 2:  1.1227e+02 -8.6394e+02  1e+03  5e-16  1e-13\n",
      " 3:  1.1217e+02  4.0577e+01  7e+01  4e-16  4e-14\n",
      " 4:  1.1070e+02  6.9383e+01  4e+01  2e-16  6e-14\n",
      " 5:  1.1026e+02  1.0158e+02  9e+00  4e-16  1e-12\n",
      " 6:  1.0980e+02  1.0546e+02  4e+00  4e-16  3e-12\n",
      " 7:  1.0949e+02  1.0890e+02  6e-01  1e-16  7e-13\n",
      " 8:  1.0938e+02  1.0932e+02  7e-02  2e-17  2e-12\n",
      " 9:  1.0936e+02  1.0936e+02  4e-03  7e-17  5e-12\n",
      "10:  1.0936e+02  1.0936e+02  2e-04  9e-17  4e-11\n",
      "11:  1.0936e+02  1.0936e+02  7e-06  1e-16  4e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.554942786693573 and untreated: 0.5522475838661194\n",
      "average propensity for treated: 0.554942786693573 and untreated: 0.5522475838661194\n",
      "average propensity for treated: 0.554942786693573 and untreated: 0.5522475838661194\n",
      "average propensity for treated: 0.554942786693573 and untreated: 0.5522475838661194\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.587428867816925 and untreated: 0.5856711864471436\n",
      "average propensity for treated: 0.5912970304489136 and untreated: 0.583184003829956\n",
      "average propensity for treated: 0.5912970304489136 and untreated: 0.583184003829956\n",
      "average propensity for treated: 0.587428867816925 and untreated: 0.5856711864471436\n",
      "Simulation 21 results:\n",
      "  Test err: 0.0822\n",
      "  Test dr_err: 0.8758\n",
      "  Test ipw_error: 0.7522\n",
      "\n",
      "Processing file 23/30: ihdp_shifted_32.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3744e+02 -4.0488e+03  1e+04  7e-02  4e-12\n",
      " 1:  1.2128e+02 -3.3964e+03  9e+03  4e-02  2e-12\n",
      " 2:  1.2385e+02 -1.0066e+03  1e+03  3e-16  2e-13\n",
      " 3:  1.2373e+02  5.5299e+01  7e+01  3e-16  2e-13\n",
      " 4:  1.2177e+02  8.5543e+01  4e+01  3e-16  3e-14\n",
      " 5:  1.2120e+02  1.1317e+02  8e+00  2e-16  2e-12\n",
      " 6:  1.2043e+02  1.1912e+02  1e+00  2e-16  3e-12\n",
      " 7:  1.2018e+02  1.1999e+02  2e-01  3e-16  4e-12\n",
      " 8:  1.2012e+02  1.2010e+02  1e-02  2e-16  4e-12\n",
      " 9:  1.2011e+02  1.2011e+02  5e-04  1e-16  1e-11\n",
      "10:  1.2011e+02  1.2011e+02  2e-05  3e-16  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2430e+02 -3.6437e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.0895e+02 -3.0341e+03  8e+03  4e-02  7e-13\n",
      " 2:  1.1053e+02 -8.7506e+02  1e+03  1e-16  2e-13\n",
      " 3:  1.1046e+02  6.3684e+01  5e+01  5e-16  1e-13\n",
      " 4:  1.0930e+02  8.9823e+01  2e+01  1e-16  3e-14\n",
      " 5:  1.0894e+02  1.0519e+02  4e+00  4e-16  2e-12\n",
      " 6:  1.0860e+02  1.0806e+02  5e-01  8e-17  6e-12\n",
      " 7:  1.0851e+02  1.0844e+02  6e-02  4e-17  7e-12\n",
      " 8:  1.0849e+02  1.0848e+02  5e-03  2e-16  1e-11\n",
      " 9:  1.0848e+02  1.0848e+02  2e-04  4e-16  6e-11\n",
      "10:  1.0848e+02  1.0848e+02  1e-05  5e-16  3e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5050486922264099 and untreated: 0.4749590754508972\n",
      "average propensity for treated: 0.5050486922264099 and untreated: 0.4749590754508972\n",
      "average propensity for treated: 0.5050486922264099 and untreated: 0.4749590754508972\n",
      "average propensity for treated: 0.5050486922264099 and untreated: 0.4749590754508972\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4445666968822479 and untreated: 0.46419307589530945\n",
      "average propensity for treated: 0.47729963064193726 and untreated: 0.45550796389579773\n",
      "average propensity for treated: 0.47729963064193726 and untreated: 0.45550796389579773\n",
      "average propensity for treated: 0.4445666968822479 and untreated: 0.46419307589530945\n",
      "Simulation 22 results:\n",
      "  Test err: 1.4005\n",
      "  Test dr_err: 0.8747\n",
      "  Test ipw_error: 1.8786\n",
      "\n",
      "Processing file 24/30: ihdp_shifted_33.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2751e+02 -3.7141e+03  1e+04  7e-02  5e-13\n",
      " 1:  1.1212e+02 -3.0975e+03  8e+03  4e-02  3e-13\n",
      " 2:  1.1439e+02 -9.0204e+02  1e+03  3e-16  2e-13\n",
      " 3:  1.1428e+02  5.2418e+01  6e+01  1e-16  5e-14\n",
      " 4:  1.1246e+02  8.0477e+01  3e+01  4e-17  4e-14\n",
      " 5:  1.1191e+02  1.0530e+02  7e+00  2e-16  2e-12\n",
      " 6:  1.1132e+02  1.1011e+02  1e+00  6e-17  3e-12\n",
      " 7:  1.1111e+02  1.1095e+02  2e-01  2e-16  3e-12\n",
      " 8:  1.1106e+02  1.1104e+02  2e-02  1e-16  6e-12\n",
      " 9:  1.1105e+02  1.1105e+02  7e-04  3e-16  1e-11\n",
      "10:  1.1105e+02  1.1105e+02  2e-05  2e-16  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3444e+02 -3.9760e+03  1e+04  7e-02  3e-12\n",
      " 1:  1.1830e+02 -3.3309e+03  9e+03  4e-02  2e-12\n",
      " 2:  1.2009e+02 -9.7848e+02  1e+03  4e-16  2e-13\n",
      " 3:  1.2002e+02  7.4896e+01  5e+01  1e-16  8e-14\n",
      " 4:  1.1872e+02  1.0320e+02  2e+01  5e-16  3e-14\n",
      " 5:  1.1820e+02  1.1534e+02  3e+00  6e-16  2e-12\n",
      " 6:  1.1784e+02  1.1741e+02  4e-01  3e-16  4e-12\n",
      " 7:  1.1774e+02  1.1769e+02  5e-02  3e-16  3e-12\n",
      " 8:  1.1772e+02  1.1772e+02  3e-03  1e-16  9e-12\n",
      " 9:  1.1772e+02  1.1772e+02  1e-04  6e-17  7e-11\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.502152681350708 and untreated: 0.48840588331222534\n",
      "average propensity for treated: 0.502152681350708 and untreated: 0.48840588331222534\n",
      "average propensity for treated: 0.502152681350708 and untreated: 0.48840588331222534\n",
      "average propensity for treated: 0.502152681350708 and untreated: 0.48840588331222534\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4784490168094635 and untreated: 0.4930732846260071\n",
      "average propensity for treated: 0.5287365913391113 and untreated: 0.44071176648139954\n",
      "average propensity for treated: 0.5287365913391113 and untreated: 0.44071176648139954\n",
      "average propensity for treated: 0.4784490168094635 and untreated: 0.4930732846260071\n",
      "Simulation 23 results:\n",
      "  Test err: 0.7743\n",
      "  Test dr_err: 1.0255\n",
      "  Test ipw_error: 0.5062\n",
      "\n",
      "Processing file 25/30: ihdp_shifted_4.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3563e+02 -4.0237e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.1964e+02 -3.3768e+03  9e+03  4e-02  6e-13\n",
      " 2:  1.2196e+02 -1.0022e+03  1e+03  2e-16  4e-13\n",
      " 3:  1.2185e+02  3.9513e+01  8e+01  2e-16  6e-14\n",
      " 4:  1.2028e+02  7.2827e+01  5e+01  1e-16  4e-14\n",
      " 5:  1.1981e+02  1.0921e+02  1e+01  8e-18  1e-12\n",
      " 6:  1.1902e+02  1.1701e+02  2e+00  1e-16  5e-12\n",
      " 7:  1.1873e+02  1.1845e+02  3e-01  1e-16  9e-13\n",
      " 8:  1.1865e+02  1.1862e+02  3e-02  3e-16  3e-12\n",
      " 9:  1.1864e+02  1.1864e+02  1e-03  3e-16  1e-11\n",
      "10:  1.1864e+02  1.1864e+02  5e-05  2e-16  1e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2702e+02 -3.6676e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1159e+02 -3.0564e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1388e+02 -8.9246e+02  1e+03  2e-16  2e-13\n",
      " 3:  1.1378e+02  4.8601e+01  7e+01  2e-16  1e-13\n",
      " 4:  1.1218e+02  7.7519e+01  3e+01  4e-16  5e-14\n",
      " 5:  1.1158e+02  1.0427e+02  7e+00  4e-16  2e-12\n",
      " 6:  1.1083e+02  1.0955e+02  1e+00  4e-16  5e-12\n",
      " 7:  1.1061e+02  1.1041e+02  2e-01  4e-16  1e-12\n",
      " 8:  1.1055e+02  1.1053e+02  2e-02  4e-17  4e-12\n",
      " 9:  1.1054e+02  1.1054e+02  8e-04  1e-16  1e-11\n",
      "10:  1.1054e+02  1.1054e+02  2e-05  5e-17  7e-11\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5687413811683655 and untreated: 0.5474106073379517\n",
      "average propensity for treated: 0.5687413811683655 and untreated: 0.5474106073379517\n",
      "average propensity for treated: 0.5687413811683655 and untreated: 0.5474106073379517\n",
      "average propensity for treated: 0.5687413811683655 and untreated: 0.5474106073379517\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.4739346206188202 and untreated: 0.48808085918426514\n",
      "average propensity for treated: 0.48408079147338867 and untreated: 0.4766751527786255\n",
      "average propensity for treated: 0.48408079147338867 and untreated: 0.4766751527786255\n",
      "average propensity for treated: 0.4739346206188202 and untreated: 0.48808085918426514\n",
      "Simulation 24 results:\n",
      "  Test err: 0.2174\n",
      "  Test dr_err: 1.0954\n",
      "  Test ipw_error: 1.8628\n",
      "\n",
      "Processing file 26/30: ihdp_shifted_5.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2840e+02 -3.7848e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1279e+02 -3.1633e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1462e+02 -9.2862e+02  1e+03  3e-16  2e-13\n",
      " 3:  1.1454e+02  5.6536e+01  6e+01  3e-16  1e-13\n",
      " 4:  1.1329e+02  8.5271e+01  3e+01  1e-16  5e-14\n",
      " 5:  1.1286e+02  1.0742e+02  5e+00  3e-16  1e-12\n",
      " 6:  1.1233e+02  1.1147e+02  9e-01  5e-16  3e-12\n",
      " 7:  1.1218e+02  1.1207e+02  1e-01  6e-16  3e-12\n",
      " 8:  1.1215e+02  1.1214e+02  1e-02  3e-16  1e-11\n",
      " 9:  1.1214e+02  1.1214e+02  4e-04  3e-16  3e-11\n",
      "10:  1.1214e+02  1.1214e+02  2e-05  1e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3163e+02 -3.9043e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.1574e+02 -3.2677e+03  8e+03  4e-02  6e-13\n",
      " 2:  1.1761e+02 -9.5856e+02  1e+03  4e-16  1e-13\n",
      " 3:  1.1752e+02  6.3774e+01  5e+01  3e-16  2e-13\n",
      " 4:  1.1622e+02  9.2901e+01  2e+01  3e-17  3e-14\n",
      " 5:  1.1573e+02  1.1108e+02  5e+00  2e-16  2e-12\n",
      " 6:  1.1525e+02  1.1448e+02  8e-01  2e-16  5e-12\n",
      " 7:  1.1510e+02  1.1501e+02  9e-02  1e-16  2e-12\n",
      " 8:  1.1507e+02  1.1507e+02  7e-03  2e-17  1e-11\n",
      " 9:  1.1507e+02  1.1507e+02  3e-04  2e-16  3e-11\n",
      "10:  1.1507e+02  1.1507e+02  1e-05  3e-17  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5099308490753174 and untreated: 0.4757755398750305\n",
      "average propensity for treated: 0.5099308490753174 and untreated: 0.4757755398750305\n",
      "average propensity for treated: 0.5099308490753174 and untreated: 0.4757755398750305\n",
      "average propensity for treated: 0.5099308490753174 and untreated: 0.4757755398750305\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.49490708112716675 and untreated: 0.5296590328216553\n",
      "average propensity for treated: 0.5689957141876221 and untreated: 0.44737887382507324\n",
      "average propensity for treated: 0.5689957141876221 and untreated: 0.44737887382507324\n",
      "average propensity for treated: 0.49490708112716675 and untreated: 0.5296590328216553\n",
      "Simulation 25 results:\n",
      "  Test err: 0.0735\n",
      "  Test dr_err: 0.1549\n",
      "  Test ipw_error: 0.8130\n",
      "\n",
      "Processing file 27/30: ihdp_shifted_6.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3117e+02 -3.8799e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.1536e+02 -3.2461e+03  8e+03  4e-02  7e-13\n",
      " 2:  1.1721e+02 -9.5073e+02  1e+03  7e-17  2e-13\n",
      " 3:  1.1713e+02  5.9761e+01  6e+01  2e-16  2e-13\n",
      " 4:  1.1578e+02  8.9247e+01  3e+01  1e-17  4e-14\n",
      " 5:  1.1539e+02  1.0997e+02  5e+00  3e-16  1e-12\n",
      " 6:  1.1488e+02  1.1403e+02  9e-01  2e-16  4e-12\n",
      " 7:  1.1473e+02  1.1463e+02  1e-01  4e-16  2e-12\n",
      " 8:  1.1470e+02  1.1469e+02  9e-03  3e-16  7e-12\n",
      " 9:  1.1470e+02  1.1470e+02  3e-04  1e-16  4e-11\n",
      "10:  1.1470e+02  1.1470e+02  1e-05  3e-16  2e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2993e+02 -3.8089e+03  1e+04  7e-02  1e-12\n",
      " 1:  1.1421e+02 -3.1836e+03  8e+03  4e-02  8e-13\n",
      " 2:  1.1620e+02 -9.3559e+02  1e+03  3e-16  2e-13\n",
      " 3:  1.1611e+02  5.9431e+01  6e+01  8e-17  7e-14\n",
      " 4:  1.1463e+02  8.7273e+01  3e+01  1e-16  6e-14\n",
      " 5:  1.1418e+02  1.0871e+02  5e+00  4e-16  1e-12\n",
      " 6:  1.1366e+02  1.1275e+02  9e-01  4e-16  3e-12\n",
      " 7:  1.1349e+02  1.1338e+02  1e-01  3e-16  2e-12\n",
      " 8:  1.1345e+02  1.1344e+02  8e-03  7e-17  9e-12\n",
      " 9:  1.1345e+02  1.1345e+02  3e-04  3e-16  3e-11\n",
      "10:  1.1345e+02  1.1345e+02  1e-05  1e-16  3e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.48656871914863586 and untreated: 0.47365185618400574\n",
      "average propensity for treated: 0.48656871914863586 and untreated: 0.47365185618400574\n",
      "average propensity for treated: 0.48656871914863586 and untreated: 0.47365185618400574\n",
      "average propensity for treated: 0.48656871914863586 and untreated: 0.47365185618400574\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5137632489204407 and untreated: 0.542050838470459\n",
      "average propensity for treated: 0.5587912201881409 and untreated: 0.49890485405921936\n",
      "average propensity for treated: 0.5587912201881409 and untreated: 0.49890485405921936\n",
      "average propensity for treated: 0.5137632489204407 and untreated: 0.542050838470459\n",
      "Simulation 26 results:\n",
      "  Test err: 0.5679\n",
      "  Test dr_err: 0.0030\n",
      "  Test ipw_error: 1.0143\n",
      "\n",
      "Processing file 28/30: ihdp_shifted_7.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3407e+02 -4.0238e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1806e+02 -3.3762e+03  9e+03  4e-02  1e-12\n",
      " 2:  1.1991e+02 -9.9561e+02  1e+03  2e-16  3e-13\n",
      " 3:  1.1983e+02  6.7784e+01  5e+01  3e-16  1e-13\n",
      " 4:  1.1844e+02  9.7005e+01  2e+01  1e-16  4e-14\n",
      " 5:  1.1799e+02  1.1403e+02  4e+00  2e-16  2e-12\n",
      " 6:  1.1757e+02  1.1698e+02  6e-01  3e-16  4e-12\n",
      " 7:  1.1746e+02  1.1739e+02  7e-02  1e-16  2e-12\n",
      " 8:  1.1743e+02  1.1743e+02  6e-03  2e-16  9e-12\n",
      " 9:  1.1743e+02  1.1743e+02  2e-04  6e-17  5e-11\n",
      "10:  1.1743e+02  1.1743e+02  1e-05  2e-16  3e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2823e+02 -3.6678e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.1258e+02 -3.0541e+03  8e+03  4e-02  1e-12\n",
      " 2:  1.1463e+02 -8.8810e+02  1e+03  4e-16  2e-13\n",
      " 3:  1.1453e+02  5.7488e+01  6e+01  3e-16  1e-13\n",
      " 4:  1.1319e+02  8.5098e+01  3e+01  7e-17  2e-14\n",
      " 5:  1.1263e+02  1.0698e+02  6e+00  2e-16  1e-12\n",
      " 6:  1.1199e+02  1.1107e+02  9e-01  4e-16  3e-12\n",
      " 7:  1.1179e+02  1.1167e+02  1e-01  2e-16  2e-12\n",
      " 8:  1.1175e+02  1.1174e+02  1e-02  5e-17  7e-12\n",
      " 9:  1.1175e+02  1.1174e+02  4e-04  1e-16  2e-11\n",
      "10:  1.1174e+02  1.1174e+02  1e-05  1e-16  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.4842338263988495 and untreated: 0.4659055769443512\n",
      "average propensity for treated: 0.4842338263988495 and untreated: 0.4659055769443512\n",
      "average propensity for treated: 0.4842338263988495 and untreated: 0.4659055769443512\n",
      "average propensity for treated: 0.4842338263988495 and untreated: 0.4659055769443512\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.43756821751594543 and untreated: 0.4457480311393738\n",
      "average propensity for treated: 0.45196396112442017 and untreated: 0.4598497748374939\n",
      "average propensity for treated: 0.45196396112442017 and untreated: 0.4598497748374939\n",
      "average propensity for treated: 0.43756821751594543 and untreated: 0.4457480311393738\n",
      "Simulation 27 results:\n",
      "  Test err: 0.6125\n",
      "  Test dr_err: 0.4816\n",
      "  Test ipw_error: 0.8313\n",
      "\n",
      "Processing file 29/30: ihdp_shifted_8.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2853e+02 -3.7854e+03  1e+04  7e-02  6e-13\n",
      " 1:  1.1281e+02 -3.1663e+03  8e+03  4e-02  4e-13\n",
      " 2:  1.1458e+02 -9.3876e+02  1e+03  7e-17  2e-13\n",
      " 3:  1.1450e+02  5.9864e+01  5e+01  3e-16  2e-13\n",
      " 4:  1.1334e+02  8.8018e+01  3e+01  2e-16  3e-14\n",
      " 5:  1.1291e+02  1.0787e+02  5e+00  8e-17  2e-12\n",
      " 6:  1.1245e+02  1.1166e+02  8e-01  1e-16  6e-12\n",
      " 7:  1.1231e+02  1.1222e+02  9e-02  1e-16  2e-12\n",
      " 8:  1.1228e+02  1.1227e+02  6e-03  2e-16  8e-12\n",
      " 9:  1.1228e+02  1.1228e+02  2e-04  1e-16  3e-11\n",
      "10:  1.1228e+02  1.1228e+02  8e-06  3e-16  3e-10\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3184e+02 -3.9037e+03  1e+04  7e-02  3e-12\n",
      " 1:  1.1597e+02 -3.2687e+03  8e+03  4e-02  2e-12\n",
      " 2:  1.1782e+02 -9.6196e+02  1e+03  5e-16  2e-13\n",
      " 3:  1.1774e+02  5.8655e+01  6e+01  2e-16  9e-14\n",
      " 4:  1.1654e+02  8.7940e+01  3e+01  4e-16  4e-14\n",
      " 5:  1.1610e+02  1.1009e+02  6e+00  3e-16  1e-12\n",
      " 6:  1.1554e+02  1.1456e+02  1e+00  2e-16  2e-12\n",
      " 7:  1.1537e+02  1.1525e+02  1e-01  3e-16  3e-12\n",
      " 8:  1.1533e+02  1.1532e+02  1e-02  8e-17  7e-12\n",
      " 9:  1.1533e+02  1.1533e+02  4e-04  1e-16  3e-11\n",
      "10:  1.1533e+02  1.1533e+02  1e-05  2e-16  2e-10\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.5082513093948364 and untreated: 0.498983234167099\n",
      "average propensity for treated: 0.5082513093948364 and untreated: 0.498983234167099\n",
      "average propensity for treated: 0.5082513093948364 and untreated: 0.498983234167099\n",
      "average propensity for treated: 0.5082513093948364 and untreated: 0.498983234167099\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5106666684150696 and untreated: 0.5390936732292175\n",
      "average propensity for treated: 0.533345103263855 and untreated: 0.5162387490272522\n",
      "average propensity for treated: 0.533345103263855 and untreated: 0.5162387490272522\n",
      "average propensity for treated: 0.5106666684150696 and untreated: 0.5390936732292175\n",
      "Simulation 28 results:\n",
      "  Test err: 0.0044\n",
      "  Test dr_err: 0.2237\n",
      "  Test ipw_error: 0.2701\n",
      "\n",
      "Processing file 30/30: ihdp_shifted_9.csv\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4642e+02 -4.4165e+03  1e+04  7e-02  9e-13\n",
      " 1:  1.2973e+02 -3.7287e+03  1e+04  4e-02  5e-13\n",
      " 2:  1.3251e+02 -1.1235e+03  1e+03  4e-16  2e-13\n",
      " 3:  1.3239e+02  4.9240e+01  8e+01  8e-17  8e-14\n",
      " 4:  1.3049e+02  8.3705e+01  5e+01  3e-17  5e-14\n",
      " 5:  1.2982e+02  1.1983e+02  1e+01  1e-16  2e-12\n",
      " 6:  1.2887e+02  1.2691e+02  2e+00  3e-16  4e-12\n",
      " 7:  1.2855e+02  1.2825e+02  3e-01  2e-16  2e-12\n",
      " 8:  1.2846e+02  1.2843e+02  3e-02  1e-16  2e-12\n",
      " 9:  1.2845e+02  1.2845e+02  1e-03  8e-17  1e-11\n",
      "10:  1.2845e+02  1.2845e+02  3e-05  4e-16  8e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1540e+02 -3.2991e+03  1e+04  7e-02  2e-12\n",
      " 1:  1.0060e+02 -2.7296e+03  7e+03  4e-02  1e-12\n",
      " 2:  1.0195e+02 -7.8203e+02  9e+02  8e-17  4e-13\n",
      " 3:  1.0188e+02  6.2127e+01  4e+01  1e-16  6e-14\n",
      " 4:  1.0101e+02  8.6797e+01  1e+01  2e-16  2e-14\n",
      " 5:  1.0070e+02  9.8236e+01  2e+00  1e-16  1e-12\n",
      " 6:  1.0045e+02  1.0015e+02  3e-01  8e-17  4e-12\n",
      " 7:  1.0039e+02  1.0036e+02  3e-02  3e-17  7e-12\n",
      " 8:  1.0038e+02  1.0038e+02  2e-03  2e-16  2e-11\n",
      " 9:  1.0038e+02  1.0038e+02  8e-05  4e-16  7e-11\n",
      "Optimal solution found.\n",
      "Is targeted regularization: False\n",
      "Creating DragonNet model\n",
      "average propensity for treated: 0.44779515266418457 and untreated: 0.435702919960022\n",
      "average propensity for treated: 0.44779515266418457 and untreated: 0.435702919960022\n",
      "average propensity for treated: 0.44779515266418457 and untreated: 0.435702919960022\n",
      "average propensity for treated: 0.44779515266418457 and untreated: 0.435702919960022\n",
      "Creating DragonNet_transfer model\n",
      "average propensity for treated: 0.5349586009979248 and untreated: 0.5420929193496704\n",
      "average propensity for treated: 0.5387709736824036 and untreated: 0.5323471426963806\n",
      "average propensity for treated: 0.5387709736824036 and untreated: 0.5323471426963806\n",
      "average propensity for treated: 0.5349586009979248 and untreated: 0.5420929193496704\n",
      "Simulation 29 results:\n",
      "  Test err: 0.1254\n",
      "  Test dr_err: 1.4498\n",
      "  Test ipw_error: 2.2438\n",
      "\n",
      "==============================\n",
      "Error Summary for All Simulations:\n",
      "Successful runs: 30/30\n",
      "ATE Error: Mean = 0.6506, Variance = 0.2327\n",
      "DR Error: Mean = 0.6718, Variance = 0.3504\n",
      "IPW Error: Mean = 1.3028, Variance = 1.4766\n",
      "Results saved to ./KMMT0T1params_target3/DA2experiments_transfer_dragonnet_8_0.01_0.001.json\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_base_dir', type=str, help=\"path to directory LBIDD\", default=\"/Users/asus/Desktop/datasets\")\n",
    "    parser.add_argument('--knob', type=str, default='dragonnet',\n",
    "                        help=\"dragonnet or tarnet\")\n",
    "\n",
    "    parser.add_argument('--output_base_dir', type=str, help=\"directory to save the output\",default=\"/Users/asus/Desktop/datasets\")\n",
    "\n",
    "    parser.add_argument('--transfer_lr',type = float,default=0.001)\n",
    "\n",
    "    parser.add_argument('--l1reg',type = float,default=0.01)\n",
    "\n",
    "    parser.add_argument('--batchsize',type = int,default=64)\n",
    "    #args = parser.parse_args(args=[])\n",
    "    #args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    turn_knob(args.data_base_dir, args.knob, args.output_base_dir,args.transfer_lr, args.l1reg,args.batchsize)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa1a6d-185a-4cbb-bc09-f0f7034e5c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a9ab9-7d3f-44b0-85a2-92ca69137897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
